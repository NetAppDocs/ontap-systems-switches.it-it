---
permalink: switch-nvidia-sn2100/migrate-cn1610-sn2100-cluster-switch.html 
sidebar: sidebar 
keywords: migrate cluster NVIDIA SN2100 cluster switches cn1610 
summary: È possibile eseguire la migrazione senza interruzioni degli switch cluster CN1610 NetApp per un cluster ONTAP agli switch di rete del cluster NVIDIA SN2100. 
---
= Migrare gli switch del cluster CN1610 agli switch del cluster NVIDIA SN2100
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
È possibile migrare gli switch cluster CN1610 di NetApp per un cluster ONTAP agli switch cluster NVIDIA SN2100. Si tratta di una procedura senza interruzioni.



== Verifica dei requisiti

Quando si sostituiscono gli switch del cluster NetApp CN1610 con gli switch del cluster NVIDIA SN2100, è necessario conoscere alcune informazioni di configurazione, le connessioni delle porte e i requisiti di cablaggio. Vedere link:configure-overview-sn2100-cluster.html["Panoramica dell'installazione e della configurazione degli switch NVIDIA SN2100"].

.Switch supportati
Sono supportati i seguenti switch del cluster:

* NetApp CN1610
* NVIDIA SN2100


Per informazioni dettagliate sulle porte supportate e sulle relative configurazioni, consultare https://hwu.netapp.com/["Hardware Universe"^].

.Di cosa hai bisogno
Verificare che la configurazione soddisfi i seguenti requisiti:

* Il cluster esistente è configurato e funziona correttamente.
* Tutte le porte del cluster sono nello stato *up* per garantire operazioni senza interruzioni.
* Gli switch del cluster NVIDIA SN2100 sono configurati e funzionano con la versione corretta di Cumulus Linux installata con il file di configurazione di riferimento (RCF) applicato.
* La configurazione di rete del cluster esistente presenta quanto segue:
+
** Un cluster NetApp ridondante e completamente funzionale che utilizza switch CN1610.
** Connettività di gestione e accesso alla console sia per gli switch CN1610 che per i nuovi switch.
** Tutte le LIF del cluster in stato up con le LIF del cluster sulle porte home.
** Porte ISL abilitate e cablate tra gli switch CN1610 e tra i nuovi switch.


* Alcune porte sono configurate sugli switch NVIDIA SN2100 per funzionare a 40 GbE o 100 GbE.
* Hai pianificato, migrato e documentato la connettività da 40 GbE e 100 GbE dai nodi agli switch cluster NVIDIA SN2100.




== Migrare gli switch

.A proposito degli esempi
Gli esempi di questa procedura utilizzano la seguente nomenclatura di switch e nodi:

* Gli switch del cluster CN1610 esistenti sono _c1_ e _c2_.
* I nuovi switch cluster NVIDIA SN2100 sono _sw1_ e _sw2_.
* I nodi sono _node1_ e _node2_.
* I LIF del cluster sono _node1_clus1_ e _node1_clus2_ sul nodo 1, e _node2_clus1_ e _node2_clus2_ rispettivamente sul nodo 2.
* Il `cluster1::*>` prompt indica il nome del cluster.
* Le porte del cluster utilizzate in questa procedura sono _e3a_ e _e3b_.
* Le porte breakout hanno il formato: swp[port]s[breakout port 0-3]. Ad esempio, quattro porte di breakout su swp1 sono _swp1s0_, _swp1s1_, _swp1s2_ e _swp1s3_.
* L'interruttore c2 viene sostituito dall'interruttore sw2, quindi l'interruttore c1 viene sostituito dall'interruttore sw1.
+
** Il cablaggio tra i nodi e c2 viene quindi scollegato da c2 e ricollegato a sw2.
** Il cablaggio tra i nodi e c1 viene quindi scollegato da c1 e ricollegato a sw1.






=== Fase 1: Preparazione per la migrazione

. Se AutoSupport è attivato su questo cluster, eliminare la creazione automatica del caso richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
dove _x_ è la durata della finestra di manutenzione in ore.

. Impostare il livello di privilegio su Advanced (avanzato), immettendo *y* quando viene richiesto di continuare:
+
`set -privilege advanced`

+
Viene visualizzato il prompt Advanced (*>).

. Disattivare il ripristino automatico sulle LIF del cluster:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
====




=== Fase 2: Configurare le porte e il cablaggio

. Determinare lo stato amministrativo o operativo di ciascuna interfaccia del cluster.
+
Ogni porta deve essere visualizzata per `Link` e. `healthy` per `Health Status`.

+
.. Visualizzare gli attributi della porta di rete:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
.. Visualizzare le informazioni relative ai LIF e ai relativi nodi principali designati:
+
`network interface show -vserver Cluster`

+
Viene visualizzato ciascun LIF `up/up` per `Status Admin/Oper` e. `true` per `Is Home`.

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical      Status     Network            Current     Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node        Port    Home
----------- -----------  ---------- ------------------ ----------- ------- ----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1       e3a     true
            node1_clus2  up/up      169.254.49.125/16  node1       e3b     true
            node2_clus1  up/up      169.254.47.194/16  node2       e3a     true
            node2_clus2  up/up      169.254.19.183/16  node2       e3b     true

----
====


. Le porte del cluster su ciascun nodo sono collegate agli switch del cluster esistenti nel seguente modo (dal punto di vista dei nodi) utilizzando il comando:
+
`network device-discovery show -protocol`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /cdp
            e3a    c1 (6a:ad:4f:98:3b:3f)    0/1               -
            e3b    c2 (6a:ad:4f:98:4c:a4)    0/1               -
node2      /cdp
            e3a    c1 (6a:ad:4f:98:3b:3f)    0/2               -
            e3b    c2 (6a:ad:4f:98:4c:a4)    0/2               -
----
====
. Le porte e gli switch del cluster sono collegati nel seguente modo (dal punto di vista degli switch) utilizzando il comando:
+
`show cdp neighbors`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
c1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 0/1           124     H          AFF-A400         e3a
node2                 0/2           124     H          AFF-A400         e3a
c2                    0/13          179     S I s      CN1610           0/13
c2                    0/14          175     S I s      CN1610           0/14
c2                    0/15          179     S I s      CN1610           0/15
c2                    0/16          175     S I s      CN1610           0/16

c2# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute


Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 0/1           124    H           AFF-A400         e3b
node2                 0/2           124    H           AFF-A400         e3b
c1                    0/13          175    S I s       CN1610           0/13
c1                    0/14          175    S I s       CN1610           0/14
c1                    0/15          175    S I s       CN1610           0/15
c1                    0/16          175    S I s       CN1610           0/16
----
====
. Verificare che la rete del cluster disponga della connettività completa utilizzando il comando:
+
`cluster ping-cluster -node node-name`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node node2*

Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1     e3a
Cluster node1_clus2 169.254.49.125 node1     e3b
Cluster node2_clus1 169.254.47.194 node2     e3a
Cluster node2_clus2 169.254.19.183 node2     e3b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
====
. Sullo switch c2, spegnere le porte collegate alle porte del cluster dei nodi.
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
(c2)# *configure*
(c2)(Config)# *interface 0/1-0/12*
(c2)(Interface 0/1-0/12)# *shutdown*
(c2)(Interface 0/1-0/12)# *exit*
(c2)(Config)# *exit*
(c2)#
----
====
. Spostare le porte del cluster di nodi dal vecchio switch c2 al nuovo switch sw2, utilizzando il cablaggio appropriato supportato da NVIDIA SN2100.
. Visualizzare gli attributi della porta di rete:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
. Le porte del cluster su ciascun nodo sono ora collegate agli switch del cluster nel seguente modo, dal punto di vista dei nodi:
+
`network device-discovery show -protocol`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   0/1               -
            e3b    sw2 (b8:ce:f6:19:1a:7e)   swp3              -
node2      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   0/2               -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4              -
----
====
. Sullo switch sw2, verificare che tutte le porte del cluster di nodi siano in funzione:
+
`net show interface`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
====
. Sullo switch c1, spegnere le porte collegate alle porte del cluster dei nodi.
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
(c1)# *configure*
(c1)(Config)# *interface 0/1-0/12*
(c1)(Interface 0/1-0/12)# *shutdown*
(c1)(Interface 0/1-0/12)# *exit*
(c1)(Config)# *exit*
(c1)#
----
====
. Spostare le porte del cluster di nodi dal vecchio switch c1 al nuovo switch sw1, utilizzando il cablaggio appropriato supportato da NVIDIA SN2100.
. Verificare la configurazione finale del cluster:
+
`network port show -ipspace Cluster`

+
Ogni porta dovrebbe essere visualizzata `up` per `Link` e. `healthy` per `Health Status`.

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
. Le porte del cluster su ciascun nodo sono ora collegate agli switch del cluster nel seguente modo, dal punto di vista dei nodi:
+
`network device-discovery show -protocol`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface       Platform
----------- ------ ------------------------- --------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3            -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4            -
----
====
. Sugli switch sw1 e sw2, verificare che tutte le porte del cluster di nodi siano in funzione:
+
`net show interface`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw2 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw2 (swp16)       Master: cluster_isl(UP)


cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- -----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
====
. Verificare che entrambi i nodi dispongano di una connessione a ciascuno switch:
+
`net show lldp`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra i risultati appropriati per entrambi gli switch:

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3a
swp4       100G   Trunk/L2    node2               e3a
swp15      100G   BondMember  sw2                 swp15
swp16      100G   BondMember  sw2                 swp16

cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3b
swp4       100G   Trunk/L2    node2               e3b
swp15      100G   BondMember  sw1                 swp15
swp16      100G   BondMember  sw1                 swp16
----
====




=== Fase 3: Completare la procedura

. Abilitare il ripristino automatico sulle LIF del cluster:
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Verificare che tutte le LIF della rete del cluster siano nuovamente presenti sulle porte domestiche:
+
`network interface show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true
----
====
. Attivare la funzione di raccolta dei log dello switch Ethernet per la raccolta dei file di log relativi allo switch, utilizzando i due comandi:
+
`system switch ethernet log setup-password` e. `system switch ethernet log enable-collection`

+
.. Inserire: `system switch ethernet log setup-password`
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log setup-password*
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
*sw1*
*sw2*

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>
----
====
.. Seguito da: `system switch ethernet log enable-collection`
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system  switch ethernet log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
====
+

NOTE: Se uno di questi comandi restituisce un errore, contattare il supporto NetApp.



. Avviare la funzione di raccolta dei log dello switch:
+
`system switch ethernet log collect -device *`

+
Attendere 10 minuti, quindi verificare che la raccolta dei log sia stata eseguita correttamente utilizzando il comando:

+
`system switch ethernet log show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> system switch ethernet log show
Log Collection Enabled: true

Index  Switch                       Log Timestamp        Status
------ ---------------------------- -------------------  ---------    
1      sw1 (b8:ce:f6:19:1b:42)      4/29/2022 03:05:25   complete   
2      sw2 (b8:ce:f6:19:1b:96)      4/29/2022 03:07:42   complete
----
====
. Modificare nuovamente il livello di privilegio in admin:
+
`set -privilege admin`

. Se è stata eliminata la creazione automatica del caso, riattivarla richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=END`


