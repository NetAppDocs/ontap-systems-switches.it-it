---
permalink: switch-nvidia-sn2100/migrate-cisco-sn2100-cluster-switch.html 
sidebar: sidebar 
keywords: migrating to a cluster with NVIDIA SN2100 cluster switches, how to migrate 
summary: È possibile migrare i vecchi switch cluster Cisco non disruptivi per un cluster ONTAP verso switch di rete cluster NVIDIA SN2100. 
---
= Migrazione da uno switch cluster Cisco a uno switch cluster NVIDIA SN2100
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
È possibile migrare gli switch cluster Cisco per un cluster ONTAP verso gli switch cluster NVIDIA SN2100. Si tratta di una procedura non distruttiva.



== Requisiti di revisione

Quando si sostituiscono alcuni vecchi switch cluster Cisco con switch cluster NVIDIA SN2100, è necessario conoscere alcune informazioni sulla configurazione, sui collegamenti delle porte e sui requisiti di cablaggio. Vederelink:configure-overview-sn2100-cluster.html["Panoramica dell'installazione e della configurazione degli switch NVIDIA SN2100"] .

.Switch supportati
Sono supportati i seguenti switch cluster Cisco :

* Nexus 9336C-FX2
* Nexus 92300YC
* Nexus 5596UP
* Nexus 3232C
* Nexus 3132Q-V


Per i dettagli sulle porte supportate e le relative configurazioni, vedere https://hwu.netapp.com/["Hardware Universe"^] .

.Cosa ti servirà
Assicurarsi che:

* Il cluster esistente è configurato e funzionante correttamente.
* Tutte le porte del cluster sono nello stato *attivo* per garantire operazioni senza interruzioni.
* Gli switch cluster NVIDIA SN2100 sono configurati e funzionano con la versione corretta di Cumulus Linux installata con il file di configurazione di riferimento (RCF) applicato.
* La configurazione di rete del cluster esistente presenta quanto segue:
+
** Un cluster NetApp ridondante e completamente funzionale che utilizza entrambi gli switch Cisco più vecchi.
** Connettività di gestione e accesso alla console sia per i vecchi switch Cisco sia per quelli nuovi.
** Tutti i cluster LIF nello stato attivo con i cluster LIf sulle loro porte home.
** Porte ISL abilitate e cablate tra i vecchi switch Cisco e tra i nuovi switch.


* Alcune porte sono configurate sugli switch NVIDIA SN2100 per funzionare a 40 GbE o 100 GbE.
* Hai pianificato, migrato e documentato la connettività 40 GbE e 100 GbE dai nodi agli switch cluster NVIDIA SN2100.



NOTE: Se si modifica la velocità delle porte cluster e0a ed e1a sui sistemi AFF A800 o AFF C800 , è possibile che vengano ricevuti pacchetti malformati dopo la conversione della velocità.  Vedere https://mysupport.netapp.com/site/bugs-online/product/ONTAP/BURT/1570339["Errore 1570339"^] e l'articolo della Knowledge Base https://kb.netapp.com/onprem/ontap/hardware/CRC_errors_on_T6_ports_after_converting_from_40GbE_to_100GbE["Errori CRC sulle porte T6 dopo la conversione da 40 GbE a 100 GbE"^] per avere una guida.



== Migrare gli switch

.Informazioni sugli esempi
In questa procedura, per i comandi e gli output di esempio vengono utilizzati gli switch cluster Cisco Nexus 3232C.

Gli esempi in questa procedura utilizzano la seguente nomenclatura di switch e nodi:

* Gli switch cluster Cisco Nexus 3232C esistenti sono _c1_ e _c2_.
* I nuovi switch cluster NVIDIA SN2100 sono _sw1_ e _sw2_.
* I nodi sono _node1_ e _node2_.
* I LIF del cluster sono _node1_clus1_ e _node1_clus2_ sul nodo 1, e _node2_clus1_ e _node2_clus2_ sul nodo 2, rispettivamente.
* IL `cluster1::*>` il prompt indica il nome del cluster.
* Le porte del cluster utilizzate in questa procedura sono _e3a_ e _e3b_.
* Le porte breakout hanno il formato: swp[porta]s[porta breakout 0-3].  Ad esempio, quattro porte breakout su swp1 sono _swp1s0_, _swp1s1_, _swp1s2_ e _swp1s3_.


.Informazioni su questo compito
Questa procedura copre il seguente scenario:

* Lo switch c2 viene sostituito prima dallo switch sw2.
+
** Chiudere le porte verso i nodi del cluster.  Per evitare l'instabilità del cluster, tutte le porte devono essere chiuse contemporaneamente.
** Il cablaggio tra i nodi e c2 viene quindi scollegato da c2 e ricollegato a sw2.


* L'interruttore c1 è sostituito dall'interruttore sw1.
+
** Chiudere le porte verso i nodi del cluster.  Per evitare l'instabilità del cluster, tutte le porte devono essere chiuse contemporaneamente.
** Il cablaggio tra i nodi e c1 viene quindi scollegato da c1 e ricollegato a sw1.






=== Fase 1: Prepararsi alla migrazione

. Se AutoSupport è abilitato su questo cluster, sopprimere la creazione automatica dei casi richiamando un messaggio AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
dove _x_ è la durata della finestra di manutenzione in ore.

. Modificare il livello di privilegio in avanzato, immettendo *y* quando richiesto per continuare:
+
`set -privilege advanced`

+
Viene visualizzato il prompt avanzato (*>).

. Disabilitare il ripristino automatico sui LIF del cluster:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`





=== Passaggio 2: configurare porte e cablaggio

. Determinare lo stato amministrativo o operativo per ciascuna interfaccia del cluster.
+
Ogni porta dovrebbe essere visualizzata per `Link` e sano per `Health Status` .

+
.. Visualizza gli attributi della porta di rete:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
.. Visualizza informazioni sulle interfacce logiche e sui nodi home designati:
+
`network interface show -vserver Cluster`

+
Ogni LIF dovrebbe visualizzare `up/up` per `Status Admin/Oper` e vero per `Is Home` .

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical      Status     Network            Current     Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node        Port    Home
----------- -----------  ---------- ------------------ ----------- ------- ----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1       e3a     true
            node1_clus2  up/up      169.254.49.125/16  node1       e3b     true
            node2_clus1  up/up      169.254.47.194/16  node2       e3a     true
            node2_clus2  up/up      169.254.19.183/16  node2       e3b     true

----
====


. Le porte del cluster su ciascun nodo sono collegate agli switch del cluster esistenti nel modo seguente (dal punto di vista dei nodi):
+
`network device-discovery show -protocol lldp`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /lldp
            e3a    c1 (6a:ad:4f:98:3b:3f)    Eth1/1            -
            e3b    c2 (6a:ad:4f:98:4c:a4)    Eth1/1            -
node2      /lldp
            e3a    c1 (6a:ad:4f:98:3b:3f)    Eth1/2            -
            e3b    c2 (6a:ad:4f:98:4c:a4)    Eth1/2            -
----
====
. Le porte e gli switch del cluster sono collegati nel modo seguente (dal punto di vista degli switch):
+
`show cdp neighbors`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
c1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 Eth1/1         124   H           AFF-A400         e3a
node2                 Eth1/2         124   H           AFF-A400         e3a
c2                    Eth1/31        179   S I s       N3K-C3232C       Eth1/31
c2                    Eth1/32        175   S I s       N3K-C3232C       Eth1/32

c2# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute


Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 Eth1/1        124    H           AFF-A400         e3b
node2                 Eth1/2        124    H           AFF-A400         e3b
c1                    Eth1/31       175    S I s       N3K-C3232C       Eth1/31
c1                    Eth1/32       175    S I s       N3K-C3232C       Eth1/32
----
====
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
Puoi usare il `network interface check cluster-connectivity` comando per avviare un controllo di accessibilità per la connettività del cluster e quindi visualizzare i dettagli:

`network interface check cluster-connectivity start`E `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* Attendere alcuni secondi prima di eseguire il `show` comando per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Tutte le versioni ONTAP
--
Per tutte le versioni ONTAP , è anche possibile utilizzare `cluster ping-cluster -node <name>` comando per verificare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1     e3a
Cluster node1_clus2 169.254.49.125 node1     e3b
Cluster node2_clus1 169.254.47.194 node2     e3a
Cluster node2_clus2 169.254.19.183 node2     e3b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[step5]] Sullo switch c2, spegnere le porte connesse alle porte del cluster dei nodi per eseguire il failover dei LIF del cluster.
+
[listing, subs="+quotes"]
----
(c2)# *configure*
Enter configuration commands, one per line. End with CNTL/Z.

(c2)(Config)# *interface*
(c2)(config-if-range)# *shutdown _<interface_list>_*
(c2)(config-if-range)# *exit*
(c2)(Config)# *exit*
(c2)#
----
. Spostare le porte del cluster di nodi dal vecchio switch c2 al nuovo switch sw2, utilizzando un cablaggio appropriato supportato da NVIDIA SN2100.
. Visualizza gli attributi della porta di rete:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
. Le porte del cluster su ciascun nodo sono ora collegate agli switch del cluster nel modo seguente, dal punto di vista dei nodi:
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   Eth1/1            -
            e3b    sw2 (b8:ce:f6:19:1a:7e)   swp3              -
node2      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   Eth1/2            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4              -
----
====
. Sullo switch sw2, verificare che tutte le porte del cluster dei nodi siano attive:
+
`net show interface`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
====
. Sullo switch c1, chiudere le porte collegate alle porte del cluster dei nodi per eseguire il failover dei LIF del cluster.
+
[listing, subs="+quotes"]
----
(c1)# *configure*
Enter configuration commands, one per line. End with CNTL/Z.

(c1)(Config)# *interface*
(c1)(config-if-range)# *shutdown _<interface_list>_*
(c1)(config-if-range)# *exit*
(c1)(Config)# *exit*
(c1)#
----
. Spostare le porte del cluster di nodi dal vecchio switch c1 al nuovo switch sw1, utilizzando un cablaggio appropriato supportato da NVIDIA SN2100.
. Verificare la configurazione finale del cluster:
+
`network port show -ipspace Cluster`

+
Ogni porta dovrebbe visualizzare `up` per `Link` e sano per `Health Status` .

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
. Le porte del cluster su ciascun nodo sono ora collegate agli switch del cluster nel modo seguente, dal punto di vista dei nodi:
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface       Platform
----------- ------ ------------------------- --------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3            -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4            -
----
====
. Sugli switch sw1 e sw2, verificare che tutte le porte del cluster di nodi siano attive:
+
`net show interface`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw2 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw2 (swp16)       Master: cluster_isl(UP)


cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- -----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
====
. Verificare che entrambi i nodi abbiano una connessione a ciascun switch:
+
`net show lldp`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra i risultati appropriati per entrambi gli switch:

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3a
swp4       100G   Trunk/L2    node2               e3a
swp15      100G   BondMember  sw2                 swp15
swp16      100G   BondMember  sw2                 swp16

cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3b
swp4       100G   Trunk/L2    node2               e3b
swp15      100G   BondMember  sw1                 swp15
swp16      100G   BondMember  sw1                 swp16
----
====




=== Passaggio 3: verificare la configurazione

. Abilita il ripristino automatico sui LIF del cluster:
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Verificare che tutti i LIF della rete cluster siano di nuovo sulle loro porte home:
+
`network interface show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true
----
====
. Ripristinare il livello di privilegio su amministratore:
+
`set -privilege admin`

. Se hai disattivato la creazione automatica dei casi, riattivala richiamando un messaggio AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.Cosa succederà ora?
Dopo aver migrato gli switch, puoi link:../switch-cshm/config-overview.html["configurare il monitoraggio dello stato dello switch"].
