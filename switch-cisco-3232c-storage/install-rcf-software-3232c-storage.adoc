---
permalink: switch-cisco-3232c-storage/install-rcf-software-3232c-storage.html 
sidebar: sidebar 
keywords: ssh, requirement, cluster, switch, health, monitor, cshm, log, collection, feature, cisco 3232c 
summary: 'SSH è un requisito quando si utilizzano le funzionalità Cluster Switch Health Monitor \(CSHM\) e di raccolta dei registri. Per abilitare SSH sugli switch del cluster Cisco 3232c, è necessario prima generare le chiavi SSH e poi abilitare SSH.' 
---
= Installare il file di configurazione di riferimento (RCF)
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Dopo aver configurato per la prima volta gli switch Nexus 3232C, installare il file di configurazione di riferimento (RCF).

.Prima di iniziare
Verificare le seguenti installazioni e connessioni:

* Un backup attuale della configurazione dello switch.
* Un cluster completamente funzionante (nessun errore nei log o problemi simili).
* L'attuale RCF.
* Una connessione console allo switch, necessaria durante l'installazione dell'RCF.


.Informazioni su questo compito
La procedura richiede l'uso sia dei comandi ONTAP sia dei comandi degli switch Cisco Nexus serie 3000; salvo diversa indicazione, vengono utilizzati i comandi ONTAP .

Durante questa procedura non è necessario alcun collegamento inter-switch (ISL) operativo. Ciò è voluto perché le modifiche alla versione RCF possono influire temporaneamente sulla connettività ISL. Per abilitare operazioni cluster senza interruzioni, la seguente procedura migra tutti i LIF del cluster allo switch partner operativo, eseguendo al contempo i passaggi sullo switch di destinazione.

Completare la procedura in link:prepare-install-cisco-nexus-3232c-storage.html["Prepararsi all'installazione di NX-OS e RCF"], e quindi seguire i passaggi seguenti.



== Fase 1: installare l'RCF sugli switch

. Accedi per cambiare cs2 tramite SSH o tramite una console seriale.
. Copiare l'RCF nel bootflash dello switch cs2 utilizzando uno dei seguenti protocolli di trasferimento: FTP, TFTP, SFTP o SCP. Per ulteriori informazioni sui comandi Cisco , consultare la guida appropriata nel https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Riferimento ai comandi NX-OS della serie Cisco Nexus 3000"^] .
+
.Mostra esempio
[%collapsible]
====
Questo esempio mostra come TFTP viene utilizzato per copiare un RCF nel bootflash sullo switch cs2:

[listing, subs="+quotes"]
----
cs2# *copy tftp: bootflash: vrf management*
Enter source filename: *Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt*
Enter hostname for the tftp server: *172.22.201.50*
Trying to connect to tftp server......Connection to Server Established.
TFTP get operation was successful
Copy complete, now saving to disk (please wait)...
----
====
. Applicare l'RCF precedentemente scaricato al bootflash.
+
Per ulteriori informazioni sui comandi Cisco , consultare la guida appropriata nel https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Riferimento ai comandi NX-OS della serie Cisco Nexus 3000"^] .

+
.Mostra esempio
[%collapsible]
====
Questo esempio mostra il file RCF `Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt` in fase di installazione sullo switch cs2:

[listing, subs="+quotes"]
----
cs2# *copy Nexus_3232C_RCF_v1.6-Cluster-HA-Breakout.txt running-config echo-commands*
----
====
+
[NOTE]
====
Assicuratevi di leggere attentamente le sezioni *Installation notes*, *Important Notes* e *banner* del vostro RCF. È necessario leggere e seguire queste istruzioni per verificare la corretta configurazione e il corretto funzionamento dello switch.

====
. Esaminare l'output del banner dal `show banner motd` comando.  È necessario leggere e seguire le istruzioni riportate nella sezione *Note importanti* per garantire la corretta configurazione e il corretto funzionamento dello switch.
. Verificare che la RCF sia la versione più recente corretta:
+
`show running-config`

+
Quando controlli l'output per verificare di avere l'RCF corretto, assicurati che le seguenti informazioni siano corrette:

+
** Lo striscione RCF
** Le impostazioni del nodo e della porta
** Personalizzazioni
+
L'output varia in base alla configurazione del sito.  Controllare le impostazioni della porta e fare riferimento alle note di rilascio per eventuali modifiche specifiche all'RCF installato.



. Riapplicare eventuali personalizzazioni precedenti alla configurazione dello switch.
. Salva i dettagli di configurazione di base nel `write_erase.cfg` file sul bootflash.
+
[NOTE]
====
Assicurati di configurare quanto segue: * Nome utente e password * Indirizzo IP di gestione * Gateway predefinito * Nome dello switch

====
+
`cs2# show run | section "switchname" > bootflash:write_erase.cfg`

+
`cs2# show run | section "hostname" >> bootflash:write_erase.cfg`

+
`cs2# show run | i "username admin password" >> bootflash:write_erase.cfg`

+
`cs2# show run | section "vrf context management" >> bootflash:write_erase.cfg`

+
`cs2# show run | section "interface mgmt0" >> bootflash:write_erase.cfg`

. Quando si installa RCF versione 1.12 e successive, eseguire i seguenti comandi:
+
`cs2# echo "hardware access-list tcam region racl-lite 512" >> bootflash:write_erase.cfg`

+
`cs2# echo "hardware access-list tcam region qos 256" >> bootflash:write_erase.cfg`

+
Vedi l'articolo della Knowledge Base https://kb.netapp.com/on-prem/Switches/Cisco-KBs/How_to_clear_configuration_on_a_Cisco_interconnect_switch_while_retaining_remote_connectivity["Come cancellare la configurazione su uno switch di interconnessione Cisco mantenendo la connettività remota"^] per ulteriori dettagli.

. Verificare che il `write_erase.cfg` il file è popolato come previsto:
+
`show file bootflash:write_erase.cfg`

. Emettere il `write erase` comando per cancellare la configurazione salvata corrente:
+
`cs2# *write erase*`

+
`Warning: This command will erase the startup-configuration.`

+
`Do you wish to proceed anyway? (y/n)  [n] *y*`

. Copiare la configurazione di base salvata in precedenza nella configurazione di avvio.
+
`cs2# *copy bootflash:write_erase.cfg startup-config*`

. Riavviare lo switch cs2:
+
`cs2# *reload*`

+
`This command will reboot the system. (y/n)?  [n] *y*`

. Ripetere i passaggi da 1 a 12 sullo switch cs1.
. Collegare le porte del cluster di tutti i nodi nel cluster ONTAP agli switch cs1 e cs2.




== Passaggio 2: verificare le connessioni dello switch

. Verificare che le porte dello switch collegate alle porte del cluster siano *attive*.
+
`show interface brief | grep up`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show interface brief | grep up*
.
.
Eth1/1/1      1       eth  access up      none                    10G(D) --
Eth1/1/2      1       eth  access up      none                    10G(D) --
Eth1/7        1       eth  trunk  up      none                   100G(D) --
Eth1/8        1       eth  trunk  up      none                   100G(D) --
.
.
----
====
. Verificare che l'ISL tra cs1 e cs2 sia funzionante:
+
`show port-channel summary`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/31(P)   Eth1/32(P)
cs1#
----
====
. Verificare che i LIF del cluster siano tornati alla loro porta home:
+
`network interface show -role cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -role cluster*
            Logical            Status     Network            Current             Current Is
Vserver     Interface          Admin/Oper Address/Mask       Node                Port    Home
----------- ------------------ ---------- ------------------ ------------------- ------- ----
Cluster
            cluster1-01_clus1  up/up      169.254.3.4/23     cluster1-01         e0d     true
            cluster1-01_clus2  up/up      169.254.3.5/23     cluster1-01         e0d     true
            cluster1-02_clus1  up/up      169.254.3.8/23     cluster1-02         e0d     true
            cluster1-02_clus2  up/up      169.254.3.9/23     cluster1-02         e0d     true
            cluster1-03_clus1  up/up      169.254.1.3/23     cluster1-03         e0b     true
            cluster1-03_clus2  up/up      169.254.1.1/23     cluster1-03         e0b     true
            cluster1-04_clus1  up/up      169.254.1.6/23     cluster1-04         e0b     true
            cluster1-04_clus2  up/up      169.254.1.7/23     cluster1-04         e0b     true
8 entries were displayed.
cluster1::*>
----
====
+
Se alcuni LIFS del cluster non sono tornati alle loro porte home, ripristinarli manualmente:
`network interface revert -vserver <vserver_name> -lif <lif_name>`

. Verificare che il cluster sia integro:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------- -------
cluster1-01          true    true          false
cluster1-02          true    true          false
cluster1-03          true    true          true
cluster1-04          true    true          false
4 entries were displayed.
cluster1::*>
----
====




== Passaggio 3: configura il tuo cluster ONTAP

NetApp consiglia di utilizzare System Manager per configurare nuovi cluster.

System Manager fornisce un flusso di lavoro semplice e facile per l'impostazione e la configurazione del cluster, tra cui l'assegnazione di un indirizzo IP di gestione del nodo, l'inizializzazione del cluster, la creazione di un livello locale, la configurazione dei protocolli e il provisioning dello storage iniziale.

Fare riferimento a https://docs.netapp.com/us-en/ontap/task_configure_ontap.html["Configurare ONTAP su un nuovo cluster con System Manager"] per le istruzioni di installazione.

.Cosa succederà ora?
Dopo aver installato l'RCF, puoi link:configure-ssh-keys.html["verificare la configurazione SSH"].
