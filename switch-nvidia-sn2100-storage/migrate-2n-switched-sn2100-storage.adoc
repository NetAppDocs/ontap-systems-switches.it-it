---
permalink: switch-nvidia-sn2100-storage/migrate-2n-switched-sn2100-storage.html 
sidebar: sidebar 
keywords: two-node switchless cluster environments,migrating to a two-node switched NVIDIA SN2100 cluster environment,switchless cluster environments,NVIDIA SN2100 switches 
summary: Se disponi di un ambiente cluster switchless a due nodi esistente, puoi migrare a un ambiente cluster switched a due nodi utilizzando gli switch NVIDIA SN2100 per poter scalare oltre due nodi nel cluster. 
---
= Migrare a un cluster commutato a due nodi con switch cluster NVIDIA SN2100
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Se disponi di un ambiente cluster switchless a due nodi esistente, puoi migrare a un ambiente cluster switched a due nodi utilizzando gli switch NVIDIA SN2100 per poter scalare oltre due nodi nel cluster.

La procedura da utilizzare varia a seconda che si disponga di due porte di rete cluster dedicate su ciascun controller o di una singola porta cluster su ciascun controller.  Il processo documentato funziona per tutti i nodi che utilizzano porte ottiche o Twinax, ma non è supportato su questo switch se i nodi utilizzano porte RJ45 10GBASE-T integrate per le porte della rete cluster.



== Requisiti di revisione

.Cosa ti servirà
Per la configurazione senza switch a due nodi, assicurarsi che:

* La configurazione switchless a due nodi è correttamente configurata e funzionante.
* I nodi eseguono ONTAP 9.10.1P3 e versioni successive.
* Tutte le porte del cluster sono attive.
* Tutte le interfacce logiche del cluster (LIF) sono attive e sulle loro porte home.


Per la configurazione dello switch cluster NVIDIA SN2100, assicurarsi che:

* Entrambi gli switch dispongono di connettività di rete di gestione.
* È disponibile l'accesso alla console per gli switch del cluster.
* Le connessioni tra switch e nodi NVIDIA SN2100 utilizzano cavi Twinax o in fibra.
+

NOTE: Vederelink:cabling-considerations-sn2100-storage.html["Considerazioni sul cablaggio e sulla configurazione"] per avvertenze e ulteriori dettagli.

+
IL https://hwu.netapp.com/SWITCH/INDEX["Hardware Universe - Interruttori"^] contiene maggiori informazioni sul cablaggio.

* I cavi Inter-Switch Link (ISL) sono collegati alle porte swp15 e swp16 su entrambi gli switch NVIDIA SN2100.
* La personalizzazione iniziale di entrambi gli switch SN2100 è stata completata, in modo che:
+
** Gli switch SN2100 eseguono l'ultima versione di Cumulus Linux
** I file di configurazione di riferimento (RCF) sono stati applicati agli switch
** Sui nuovi switch vengono configurate tutte le personalizzazioni del sito, come SMTP, SNMP e SSH.






== Migrare gli switch

.Informazioni sugli esempi
Gli esempi in questa procedura utilizzano la seguente nomenclatura di cluster switch e nodi:

* I nomi degli switch SN2100 sono _sw1_ e _sw2_.
* I nomi degli SVM del cluster sono _node1_ e _node2_.
* I nomi dei LIF sono _node1_clus1_ e _node1_clus2_ sul nodo 1, e _node2_clus1_ e _node2_clus2_ sul nodo 2, rispettivamente.
* IL `cluster1::*>` il prompt indica il nome del cluster.
* Le porte del cluster utilizzate in questa procedura sono _e3a_ e _e3b_.
* Le porte breakout hanno il formato: swp[porta]s[porta breakout 0-3].  Ad esempio, quattro porte breakout su swp1 sono _swp1s0_, _swp1s1_, _swp1s2_ e _swp1s3_.
+
IL https://hwu.netapp.com["Hardware Universe"^] contiene le informazioni più recenti sulle porte cluster effettive per le tue piattaforme.





=== Fase 1: Prepararsi alla migrazione

. Se AutoSupport è abilitato su questo cluster, sopprimere la creazione automatica dei casi richiamando un messaggio AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
dove _x_ è la durata della finestra di manutenzione in ore.

. Cambia il livello di privilegio in avanzato, inserendo `y` quando viene richiesto di continuare:
+
`set -privilege advanced`

+
Il prompt avanzato(`*>` ) appare.





=== Passaggio 2: configurare cavi e porte

. Disabilitare tutte le porte rivolte verso il nodo (non le porte ISL) su entrambi i nuovi switch cluster sw1 e sw2.
+
Non è consentito disattivare le porte ISL.

+
.Mostra esempio
[%collapsible]
====
I seguenti comandi disabilitano le porte rivolte al nodo sugli switch sw1 e sw2:

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net add interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*

cumulus@sw2:~$ *net add interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@sw2:~$ *net pending*
cumulus@sw2:~$ *net commit*
----
====
. Verificare che l'ISL e le porte fisiche sull'ISL tra i due switch SN2100 sw1 e sw2 siano attive sulle porte swp15 e swp16:
+
`net show interface`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra che le porte ISL sono attive sullo switch sw1:

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name       Spd   MTU    Mode        LLDP         Summary
-----  ---------  ----  -----  ----------  -----------  -----------------------
...
...
UP     swp15      100G  9216   BondMember  sw2 (swp15)  Master: cluster_isl(UP)
UP     swp16      100G  9216   BondMember  sw2 (swp16)  Master: cluster_isl(UP)
----
+ L'esempio seguente mostra che le porte ISL sono attive sullo switch sw2:

+

[listing, subs="+quotes"]
----
cumulus@sw2:~$ *net show interface*

State  Name       Spd   MTU    Mode        LLDP         Summary
-----  ---------  ----  -----  ----------  -----------  -----------------------
...
...
UP     swp15      100G  9216   BondMember  sw1 (swp15)  Master: cluster_isl(UP)
UP     swp16      100G  9216   BondMember  sw1 (swp16)  Master: cluster_isl(UP)
----
====
. Verificare che tutte le porte del cluster siano attive:
+
`network port show`

+
Ogni porta dovrebbe essere visualizzata per `Link` e sano per `Health Status` .

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show*

Node: node1

                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2

                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

----
====
. Verificare che tutti i cluster LIF siano attivi e operativi:
+
`network interface show`

+
Ogni cluster LIF dovrebbe visualizzare true per `Is Home` e avere un `Status Admin/Oper` di su/su

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- -----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true
----
====
. Disabilitare il ripristino automatico sui LIF del cluster:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

          Logical
Vserver   Interface     Auto-revert
--------- ------------- ------------
Cluster
          node1_clus1   false
          node1_clus2   false
          node2_clus1   false
          node2_clus2   false

----
====
. Scollegare il cavo dalla porta e3a del cluster sul nodo 3, quindi collegare e3a alla porta 1 sullo switch sw1 del cluster, utilizzando il cablaggio appropriato supportato dagli switch SN2100.
+
IL https://hwu.netapp.com/SWITCH/INDEX["Hardware Universe - Interruttori"^] contiene maggiori informazioni sul cablaggio.

. Scollegare il cavo dalla porta e3a del cluster sul nodo 4, quindi collegare e3a alla porta 2 sullo switch sw1 del cluster, utilizzando il cablaggio appropriato supportato dagli switch SN2100.
. Sullo switch sw1, abilitare tutte le porte rivolte verso il nodo.
+
.Mostra esempio
[%collapsible]
====
Il seguente comando abilita tutte le porte rivolte verso il nodo sullo switch sw1:

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net del interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
====
. Sullo switch sw1, verificare che tutte le porte siano attive:
+
`net show interface all`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface all*

State  Name      Spd   MTU    Mode       LLDP            Summary
-----  --------- ----  -----  ---------- --------------- --------
...
DN     swp1s0    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp1s1    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp1s2    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp1s3    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s0    25G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s1    25G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s2    25G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s3    25G   9216   Trunk/L2                   Master: br_default(UP)
UP     swp3      100G  9216   Trunk/L2    node1 (e3a)    Master: br_default(UP)
UP     swp4      100G  9216   Trunk/L2    node2 (e3a)    Master: br_default(UP)
...
...
UP     swp15     100G  9216   BondMember  swp15          Master: cluster_isl(UP)
UP     swp16     100G  9216   BondMember  swp16          Master: cluster_isl(UP)
...
----
====
. Verificare che tutte le porte del cluster siano attive:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra che tutte le porte del cluster sono attive su node1 e node2:

[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

----
====
. Visualizza informazioni sullo stato dei nodi nel cluster:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra informazioni sullo stato di integrità e sull'idoneità dei nodi nel cluster:

[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

----
====
. Scollegare il cavo dalla porta e3b del cluster sul nodo 3, quindi collegare e3b alla porta 1 sullo switch sw2 del cluster, utilizzando il cablaggio appropriato supportato dagli switch SN2100.
. Scollegare il cavo dalla porta e3b del cluster sul nodo 4, quindi collegare e3b alla porta 2 sullo switch sw2 del cluster, utilizzando il cablaggio appropriato supportato dagli switch SN2100.
. Sullo switch sw2, abilitare tutte le porte rivolte verso il nodo.
+
.Mostra esempio
[%collapsible]
====
I seguenti comandi abilitano le porte rivolte verso il nodo sullo switch sw2:

[listing, subs="+quotes"]
----
cumulus@sw2:~$ *net del interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@sw2:~$ *net pending*
cumulus@sw2:~$ *net commit*
----
====
. Sullo switch sw2, verificare che tutte le porte siano attive:
+
`net show interface all`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw2:~$ *net show interface all*

State  Name      Spd   MTU    Mode       LLDP            Summary
-----  --------- ----  -----  ---------- --------------- --------
...
DN     swp1s0    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp1s1    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp1s2    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp1s3    10G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s0    25G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s1    25G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s2    25G   9216   Trunk/L2                   Master: br_default(UP)
DN     swp2s3    25G   9216   Trunk/L2                   Master: br_default(UP)
UP     swp3      100G  9216   Trunk/L2    node1 (e3b)    Master: br_default(UP)
UP     swp4      100G  9216   Trunk/L2    node2 (e3b)    Master: br_default(UP)
...
...
UP     swp15     100G  9216   BondMember  swp15          Master: cluster_isl(UP)
UP     swp16     100G  9216   BondMember  swp16          Master: cluster_isl(UP)
...
----
====
. Su entrambi gli switch sw1 e sw2, verificare che entrambi i nodi abbiano una connessione ciascuno con ogni switch:
+
`net show lldp`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra i risultati appropriati per entrambi gli switch sw1 e sw2:

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  sw2                swp15
swp16      100G   BondMember  sw2                swp16

cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3b
swp4       100G   Trunk/L2    node2              e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
====




=== Fase 3: Completare la procedura

. Visualizza informazioni sui dispositivi di rete rilevati nel tuo cluster:
+
`net device-discovery show -protocol lldp`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3          -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4          -
----
====
. Verificare che tutte le porte del cluster siano attive:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra che tutte le porte del cluster sono attive su node1 e node2:

[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e3a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e3a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/10000 healthy  false

----
====
. Abilita il ripristino automatico su tutti i LIF del cluster:
+
`net interface modify -vserver Cluster -lif * -auto-revert true`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *net interface modify -vserver Cluster -lif * -auto-revert true*

          Logical
Vserver   Interface     Auto-revert
--------- ------------- ------------
Cluster
          node1_clus1   true
          node1_clus2   true
          node2_clus1   true
          node2_clus2   true
----
====
. Verificare che tutte le interfacce visualizzino true per `Is Home` :
+
`net interface show -vserver Cluster`

+

NOTE: Potrebbe volerci un minuto per completare l'operazione.

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra che tutti i LIF sono attivi su node1 e node2 e che `Is Home` i risultati sono veri:

[listing, subs="+quotes"]
----
cluster1::*> *net interface show -vserver Cluster*

          Logical      Status     Network            Current    Current Is
Vserver   Interface    Admin/Oper Address/Mask       Node       Port    Home
--------- ------------ ---------- ------------------ ---------- ------- ----
Cluster
          node1_clus1  up/up      169.254.209.69/16  node1      e3a     true
          node1_clus2  up/up      169.254.49.125/16  node1      e3b     true
          node2_clus1  up/up      169.254.47.194/16  node2      e3a     true
          node2_clus2  up/up      169.254.19.183/16  node2      e3b     true

----
====
. Verificare che le impostazioni siano disabilitate:
+
`network options switchless-cluster show`

+
.Mostra esempio
[%collapsible]
====
L'output false nell'esempio seguente mostra che le impostazioni di configurazione sono disabilitate:

[listing, subs="+quotes"]
----
cluster1::*> *network options switchless-cluster show*
Enable Switchless Cluster: *false*
----
====
. Verificare lo stato dei membri del nodo nel cluster:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra informazioni sullo stato di integrità e sull'idoneità dei nodi nel cluster:

[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  --------
node1                true    true          false
node2                true    true          false
----
====
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
Puoi usare il `network interface check cluster-connectivity` comando per avviare un controllo di accessibilità per la connettività del cluster e quindi visualizzare i dettagli:

`network interface check cluster-connectivity start`E `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* Attendere alcuni secondi prima di eseguire il `show` comando per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Tutte le versioni ONTAP
--
Per tutte le versioni ONTAP , è anche possibile utilizzare `cluster ping-cluster -node <name>` comando per verificare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node1
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e3a
Cluster node1_clus2 169.254.49.125 node1 e3b
Cluster node2_clus1 169.254.47.194 node2 e3a
Cluster node2_clus2 169.254.19.183 node2 e3b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:

Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)

Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[step8]] Abilitare la funzionalità di raccolta dei log del monitoraggio dello stato dello switch Ethernet per raccogliere i file di log relativi allo switch, utilizzando i comandi:
+
`system switch ethernet log setup-password`E `system switch ethernet log enable-collection`

+
Inserisci: `system switch ethernet log setup-password`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log setup-password*
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
*sw1*
*sw2*

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>
----
====
+
Seguito da:

+
`system switch ethernet log enable-collection`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
====
+

NOTE: Se uno di questi comandi restituisce un errore, contattare l'assistenza NetApp .

. Avvia la funzionalità di raccolta dei registri di commutazione:
+
`system switch ethernet log collect -device *`

+
Attendi 10 minuti e poi verifica che la raccolta dei log sia avvenuta correttamente utilizzando il comando:

+
`system switch ethernet log show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log show*
Log Collection Enabled: true

Index  Switch                       Log Timestamp        Status
------ ---------------------------- -------------------  ---------    
1      sw1 (b8:ce:f6:19:1b:42)      4/29/2022 03:05:25   complete   
2      sw2 (b8:ce:f6:19:1b:96)      4/29/2022 03:07:42   complete
----
====
. Ripristinare il livello di privilegio su amministratore:
+
`set -privilege admin`

. Se hai disattivato la creazione automatica dei casi, riattivala richiamando un messaggio AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`


