---
permalink: switch-nvidia-sn2100/replace-sn2100-switch-storage.html 
sidebar: sidebar 
keywords: replacing, replace, defective, nvidia, switch, cluster, network, nondisruptive, procedure, ndu, replace a nvidia msn2100 cluster switch - nvidia SN2100 
summary: La sostituzione di uno switch NVIDIA SN2100 difettoso in una rete cluster è una procedura senza interruzioni. 
---
= Sostituire uno switch cluster NVIDIA SN2100
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
La sostituzione di uno switch NVIDIA SN2100 difettoso in una rete cluster è una procedura senza interruzioni (NDU).

.Prima di iniziare
Prima di eseguire la sostituzione dello switch nell'ambiente corrente e sullo switch sostitutivo, devono sussistere le seguenti condizioni.

* Infrastruttura di rete e cluster esistente:
+
** Il cluster esistente deve essere verificato come completamente funzionale, con almeno uno switch del cluster completamente connesso.
** Tutte le porte del cluster devono essere installate.
** Tutte le interfacce logiche del cluster (LIFF) devono essere installate sulle porte home.
** ONTAP `cluster ping-cluster -node node1` Il comando deve indicare che la connettività di base e le comunicazioni di dimensioni superiori a quelle di PMTU hanno esito positivo su tutti i percorsi.


* Switch sostitutivo NVIDIA SN2100:
+
** La connettività di rete di gestione sullo switch sostitutivo deve essere funzionante.
** L'accesso della console allo switch sostitutivo deve essere in posizione.
** Le connessioni dei nodi sono porte da swp1 a swp14.
** Tutte le porte ISL (Inter-Switch link) devono essere disattivate sulle porte swp15 e swp16.
** Il file di configurazione di riferimento desiderato (RCF) e lo switch dell'immagine del sistema operativo Cumulus devono essere caricati sullo switch.
** La personalizzazione iniziale dello switch deve essere completata, come descritto in:
+
Eventuali personalizzazioni precedenti del sito, come STP, SNMP e SSH, devono essere copiate nel nuovo switch.





È necessario eseguire il comando per la migrazione di un LIF del cluster dal nodo in cui è ospitato il LIF del cluster.

.A proposito di questa attività
Gli esempi di questa procedura utilizzano la seguente nomenclatura di switch e nodi:

* I nomi degli switch NVIDIA SN2100 esistenti sono _sw1_ e _sw2_.
* Il nome del nuovo switch NVIDIA SN2100 è _nsw2_.
* I nomi dei nodi sono _node1_ e _node2_.
* Le porte del cluster su ciascun nodo sono denominate _e3a_ e _e3b_.
* I nomi LIF del cluster sono _node1_clus1_ e _node1_clus2_ per node1 e _node2_clus1_ e _node2_clus2_ per node2_.
* Il prompt per le modifiche a tutti i nodi del cluster è `cluster1::*>`
* Le porte breakout hanno il formato: swp[port]s[breakout port 0-3]. Ad esempio, quattro porte di breakout su swp1 sono _swp1s0_, _swp1s1_, _swp1s2_ e _swp1s3_.
+

NOTE: La seguente procedura si basa sulla seguente topologia di rete del cluster:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false


cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true


cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3          -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4          -
----
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw2                e3a
swp4       100G   Trunk/L2    sw2                e3a
swp15      100G   BondMember  sw2                swp15
swp16      100G   BondMember  sw2                swp16


cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw1                e3b
swp4       100G   Trunk/L2    sw1                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----


.Fasi
. Se AutoSupport è attivato su questo cluster, eliminare la creazione automatica del caso richiamando un messaggio AutoSupport: `system node autosupport invoke -node * -type all -message MAINT=xh`
+
dove _x_ è la durata della finestra di manutenzione in ore.

. Impostare il livello di privilegio su Advanced (avanzato), immettendo *y* quando viene richiesto di continuare: `set -privilege advanced`
+
Viene visualizzato il prompt Advanced (*>).

. Installare l'RCF e l'immagine appropriati sullo switch, nsw2, ed eseguire le operazioni necessarie per la preparazione del sito.
+
Se necessario, verificare, scaricare e installare le versioni appropriate del software RCF e Cumulus per il nuovo switch. Se si è verificato che il nuovo switch è configurato correttamente e non sono necessari aggiornamenti per il software RCF e Cumulus, passare alla fase 4. Vedere link:install_setup_sn2100_switches_overview.html["Configurare e configurare gli switch NVIDIA SN2100"] per ulteriori dettagli.

+
.. È possibile scaricare il software Cumulus applicabile per gli switch del cluster dal sito _NVIDIA Support_. Seguire la procedura indicata nella pagina di download per scaricare Cumulus Linux per la versione del software ONTAP che si sta installando.
.. L'RCF appropriato è disponibile sul sito link:https://mysupport.netapp.com/site/products/all/details/nvidia-cluster-storage-switch/downloads-tab["_Cluster NVIDIA e switch storage_"^] pagina. Seguire la procedura indicata nella pagina di download per scaricare l'RCF corretto per la versione del software ONTAP che si sta installando.


. Sul nuovo switch nsw2, accedere come admin e chiudere tutte le porte che saranno connesse alle interfacce del cluster di nodi (porte da swp1 a swp14).
+
Se lo switch che si sta sostituendo non funziona e viene spento, passare alla fase 5. Le LIF sui nodi del cluster dovrebbero essere già riuscite a eseguire il failover sull'altra porta del cluster per ciascun nodo.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net add interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Disattivare il ripristino automatico sulle LIF del cluster: `network interface modify -vserver Cluster -lif * -auto-revert false`
+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Spegnere le porte ISL swp15 e swp16 sullo switch SN2100 sw1:
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net add interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
. Rimuovere tutti i cavi dallo switch SN2100 sw1, quindi collegarli alle stesse porte dello switch SN2100 nsw2.
. Attivare le porte ISL swp15 e swp16 tra gli switch sw1 e nsw2.
+
I seguenti comandi abilitano le porte ISL swp15 e swp16 sullo switch sw1:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net del interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
+
L'esempio seguente mostra che le porte ISL sono installate sullo switch sw1:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
L'esempio seguente mostra che le porte ISL sono installate sullo switch nsw2:

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Verificare la porta `e3b` è attivo su tutti i nodi: `network port show -ipspace Cluster`
+
L'output dovrebbe essere simile a quanto segue:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Le porte del cluster su ciascun nodo sono ora collegate agli switch del cluster nel seguente modo, dal punto di vista dei nodi:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Verificare che tutte le porte del cluster di nodi siano in funzione: `net show interface`
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Verificare che entrambi i nodi dispongano di una connessione a ciascuno switch: `net show lldp`
+
L'esempio seguente mostra i risultati appropriati per entrambi gli switch:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Abilitare il ripristino automatico sulle LIF del cluster: `cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`
. Sullo switch nsw2, richiamare le porte collegate alle porte di rete dei nodi.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net del interface swp1-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Visualizzare le informazioni sui nodi di un cluster: `cluster show`
+
Questo esempio mostra che l'integrità del nodo per node1 e node2 in questo cluster è vera:

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Verificare che tutte le porte del cluster fisico siano installate: `network port show ipspace Cluster`
+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false

----
. Verificare che la rete del cluster sia in buone condizioni:
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----
. Attivare la funzione di raccolta dei log dello switch Ethernet per la raccolta dei file di log relativi allo switch, utilizzando i comandi seguenti: `system switch ethernet log setup-password` e. `system switch ethernet log enable-collection`
+
Inserire: `system switch ethernet log setup-password`

+
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log setup-password*
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
*sw1*
*nsw2*

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *nsw2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>
----
+
Seguito da: `system switch ethernet log enable-collection`

+
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
+

NOTE: Se uno di questi comandi restituisce un errore, contattare il supporto NetApp.

. Avviare la funzione di raccolta dei log dello switch: `system switch ethernet log collect -device *`
+
Attendere 10 minuti, quindi verificare che la raccolta dei log sia stata eseguita correttamente utilizzando il comando: `system switch ethernet log show`

+
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log show*
Log Collection Enabled: true

Index  Switch                       Log Timestamp        Status
------ ---------------------------- -------------------  ---------    
1      sw1 (b8:ce:f6:19:1b:42)      4/29/2022 03:05:25   complete   
2      nsw2 (b8:ce:f6:19:1b:96)     4/29/2022 03:07:42   complete
----
. Modificare nuovamente il livello di privilegio in admin: `set -privilege admin`
. Se è stata eliminata la creazione automatica del caso, riattivarla richiamando un messaggio AutoSupport: `system node autosupport invoke -node * -type all -message MAINT=END`

