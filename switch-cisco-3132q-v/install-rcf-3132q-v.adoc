---
permalink: switch-cisco-3132q-v/install-rcf-3132q-v.html 
sidebar: sidebar 
keywords: install rcf 
summary: È possibile installare RCF dopo aver configurato lo switch Nexus 3132Q-V per la prima volta. È inoltre possibile utilizzare questa procedura per aggiornare la versione di RCF. 
---
= Installazione del file di configurazione di riferimento (RCF)
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Seguire questa procedura per installare RCF dopo aver configurato lo switch Nexus 3132Q-V per la prima volta. È inoltre possibile utilizzare questa procedura per aggiornare la versione di RCF.



== Verifica dei requisiti

.Di cosa hai bisogno
* Backup corrente della configurazione dello switch.
* Un cluster completamente funzionante (nessun errore nei log o problemi simili).
* Il file di configurazione di riferimento corrente (RCF).
* Quando si installa l'RCF, è necessario collegare la console all'interruttore. Questo requisito è facoltativo se si è utilizzato l'articolo della Knowledge base https://kb.netapp.com/on-prem/Switches/Cisco-KBs/How_to_clear_configuration_on_a_Cisco_interconnect_switch_while_retaining_remote_connectivity["Come cancellare la configurazione su uno switch Cisco Interconnect mantenendo la connettività remota"^] per cancellare la configurazione, in anticipo.
* link:https://mysupport.netapp.com/site/info/cisco-ethernet-switch["Switch Ethernet Cisco"^]. Consultare la tabella di compatibilità degli switch per le versioni ONTAP e RCF supportate. Si noti che esistono dipendenze di comando tra la sintassi del comando in RCF e quella presente nelle versioni di NX-OS.
* https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Switch Cisco Nexus serie 3000"^]. Consultare le guide all'aggiornamento e al software appropriate disponibili sul sito Web di Cisco per la documentazione completa sulle procedure di aggiornamento e downgrade dello switch Cisco.




== Installare il file

.A proposito degli esempi
Gli esempi di questa procedura utilizzano la seguente nomenclatura di switch e nodi:

* I nomi dei due switch Cisco sono `cs1` e. `cs2`.
* I nomi dei nodi sono `cluster1-01`, `cluster1-02`, `cluster1-03`, e. `cluster1-04`.
* I nomi LIF del cluster sono `cluster1-01_clus1`, `cluster1-01_clus2`, `cluster1-02_clus1`, `cluster1-02_clus2` , `cluster1-03_clus1`, `cluster1-03_clus2`, `cluster1-04_clus1`, e. `cluster1-04_clus2`.
* Il `cluster1::*>` prompt indica il nome del cluster.


.A proposito di questa attività
La procedura richiede l'utilizzo di entrambi i comandi ONTAP e Cisco Nexus 3000 Series Switches; i comandi ONTAP vengono utilizzati se non diversamente indicato.

Durante questa procedura non è necessario alcun collegamento interswitch operativo (ISL). Ciò è dovuto alla progettazione, in quanto le modifiche alla versione di RCF possono influire temporaneamente sulla connettività ISL. Per garantire operazioni del cluster senza interruzioni, la seguente procedura esegue la migrazione di tutte le LIF del cluster allo switch del partner operativo durante l'esecuzione delle operazioni sullo switch di destinazione.

Assicurarsi di completare la procedura descritta in link:prepare-install-cisco-nexus-3132q.html["Preparare l'installazione del software NX-OS e del file di configurazione di riferimento"], quindi seguire la procedura riportata di seguito.



=== Fase 1: Controllare lo stato della porta

. Visualizzare le porte del cluster su ciascun nodo collegato agli switch del cluster:
+
`network device-discovery show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ------------
cluster1-01/cdp
            e0a    cs1                       Ethernet1/7       N3K-C3132Q-V
            e0d    cs2                       Ethernet1/7       N3K-C3132Q-V
cluster1-02/cdp
            e0a    cs1                       Ethernet1/8       N3K-C3132Q-V
            e0d    cs2                       Ethernet1/8       N3K-C3132Q-V
cluster1-03/cdp
            e0a    cs1                       Ethernet1/1/1     N3K-C3132Q-V
            e0b    cs2                       Ethernet1/1/1     N3K-C3132Q-V
cluster1-04/cdp
            e0a    cs1                       Ethernet1/1/2     N3K-C3132Q-V
            e0b    cs2                       Ethernet1/1/2     N3K-C3132Q-V
cluster1::*>
----
====
. Controllare lo stato amministrativo e operativo di ciascuna porta del cluster.
+
.. Verificare che tutte le porte del cluster siano funzionanti:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: cluster1-01
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false

Node: cluster1-02
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false
8 entries were displayed.

Node: cluster1-03

   Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-04
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false
cluster1::*>
----
====
.. Verificare che tutte le interfacce del cluster (LIF) siano sulla porta home:
+
`network interface show -vserver Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical            Status     Network           Current      Current Is
Vserver     Interface          Admin/Oper Address/Mask      Node         Port    Home
----------- ------------------ ---------- ----------------- ------------ ------- ----
Cluster
            cluster1-01_clus1  up/up     169.254.3.4/23     cluster1-01  e0a     true
            cluster1-01_clus2  up/up     169.254.3.5/23     cluster1-01  e0d     true
            cluster1-02_clus1  up/up     169.254.3.8/23     cluster1-02  e0a     true
            cluster1-02_clus2  up/up     169.254.3.9/23     cluster1-02  e0d     true
            cluster1-03_clus1  up/up     169.254.1.3/23     cluster1-03  e0a     true
            cluster1-03_clus2  up/up     169.254.1.1/23     cluster1-03  e0b     true
            cluster1-04_clus1  up/up     169.254.1.6/23     cluster1-04  e0a     true
            cluster1-04_clus2  up/up     169.254.1.7/23     cluster1-04  e0b     true
cluster1::*>
----
====
.. Verificare che il cluster visualizzi le informazioni per entrambi gli switch del cluster:
+
`system cluster-switch show -is-monitoring-enabled-operational true`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system cluster-switch show -is-monitoring-enabled-operational true*
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- ---------------
cs1                         cluster-network    10.0.0.1         NX3132QV
     Serial Number: FOXXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

cs2                         cluster-network    10.0.0.2         NX3132QV
     Serial Number: FOXXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

2 entries were displayed.
----
====


+

NOTE: Per ONTAP 9.8 e versioni successive, utilizzare il comando `system switch ethernet show -is-monitoring-enabled-operational true`.

. Disattiva l'autorevert sulle LIF del cluster.
+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*
----
+
Assicurarsi che l'autorevert sia disattivato dopo aver eseguito questo comando.

. Sullo switch del cluster cs2, spegnere le porte collegate alle porte del cluster dei nodi.
+
[listing, subs="+quotes"]
----
cs2(config)# *interface eth1/1/1-2,eth1/7-8*
cs2(config-if-range)# *shutdown*
----
. Verificare che le porte del cluster siano migrate alle porte ospitate sullo switch del cluster cs1. Questa operazione potrebbe richiedere alcuni secondi.
+
`network interface show -vserver Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical           Status     Network            Current       Current Is
Vserver     Interface         Admin/Oper Address/Mask       Node          Port    Home
----------- ----------------- ---------- ------------------ ------------- ------- ----
Cluster
            cluster1-01_clus1 up/up      169.254.3.4/23     cluster1-01   e0a     true
            cluster1-01_clus2 up/up      169.254.3.5/23     cluster1-01   e0a     false
            cluster1-02_clus1 up/up      169.254.3.8/23     cluster1-02   e0a     true
            cluster1-02_clus2 up/up      169.254.3.9/23     cluster1-02   e0a     false
            cluster1-03_clus1 up/up      169.254.1.3/23     cluster1-03   e0a     true
            cluster1-03_clus2 up/up      169.254.1.1/23     cluster1-03   e0a     false
            cluster1-04_clus1 up/up      169.254.1.6/23     cluster1-04   e0a     true
            cluster1-04_clus2 up/up      169.254.1.7/23     cluster1-04   e0a     false
cluster1::*>
----
====
. Verificare che il cluster funzioni correttamente:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  -------
cluster1-01          true    true          false
cluster1-02          true    true          false
cluster1-03          true    true          true
cluster1-04          true    true          false
cluster1::*>
----
====




=== Fase 2: Configurare e verificare l'installazione

. Se non è già stato fatto, salvare una copia della configurazione corrente dello switch copiando l'output del seguente comando in un file di testo:
+
`show running-config`

. Pulire la configurazione sullo switch cs2 ed eseguire una configurazione di base.
+

WARNING: Quando si aggiorna o si applica un nuovo RCF, è necessario cancellare le impostazioni dello switch ed eseguire la configurazione di base. Per configurare nuovamente lo switch, è *necessario* essere collegati alla porta seriale della console dello switch. Tuttavia, questo requisito è facoltativo se si è utilizzato l'articolo della Knowledge base https://kb.netapp.com/on-prem/Switches/Cisco-KBs/How_to_clear_configuration_on_a_Cisco_interconnect_switch_while_retaining_remote_connectivity["Come cancellare la configurazione su uno switch Cisco Interconnect mantenendo la connettività remota"^] per cancellare la configurazione, in anticipo.

+
.. Pulire la configurazione:
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
(cs2)# *write erase*

Warning: This command will erase the startup-configuration.

Do you wish to proceed anyway? (y/n)  [n]  *y*
----
====
.. Riavviare lo switch:
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
(cs2)# *reload*

Are you sure you would like to reset the system? (y/n) *y*

----
====


. Copiare l'RCF nella flash di avvio dello switch cs2 utilizzando uno dei seguenti protocolli di trasferimento: FTP, TFTP, SFTP o SCP. Per ulteriori informazioni sui comandi Cisco, consultare la guida appropriata in https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Cisco Nexus 3000 Series NX-OS Command Reference"^] guide.
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs2# *copy tftp: bootflash: vrf management*
Enter source filename: *Nexus_3132QV_RCF_v1.6-Cluster-HA-Breakout.txt*
Enter hostname for the tftp server: 172.22.201.50
Trying to connect to tftp server......Connection to Server Established.
TFTP get operation was successful
Copy complete, now saving to disk (please wait)...
----
====
. Applicare l'RCF precedentemente scaricato al bootflash.
+
Per ulteriori informazioni sui comandi Cisco, consultare la guida appropriata in https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Cisco Nexus 3000 Series NX-OS Command Reference"^] guide.

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs2# *copy Nexus_3132QV_RCF_v1.6-Cluster-HA-Breakout.txt running-config echo-commands*
----
====
. Esaminare l'output dello striscione da `show banner motd` comando. Leggere e seguire le istruzioni in *Note importanti* per garantire la corretta configurazione e il corretto funzionamento dello switch.
+
.Mostra esempio
[%collapsible]
====
[listing]
----
cs2# show banner motd

******************************************************************************
* NetApp Reference Configuration File (RCF)
*
* Switch   : Cisco Nexus 3132Q-V
* Filename : Nexus_3132QV_RCF_v1.6-Cluster-HA-Breakout.txt
* Date     : Nov-02-2020
* Version  : v1.6
*
* Port Usage : Breakout configuration
* Ports  1- 6: Breakout mode (4x10GbE) Intra-Cluster Ports, int e1/1/1-4,
* e1/2/1-4, e1/3/1-4,int e1/4/1-4, e1/5/1-4, e1/6/1-4
* Ports  7-30: 40GbE Intra-Cluster/HA Ports, int e1/7-30
* Ports 31-32: Intra-Cluster ISL Ports, int e1/31-32
*
* IMPORTANT NOTES
* - Load Nexus_3132QV_RCF_v1.6-Cluster-HA.txt for non breakout config
*
* - This RCF utilizes QoS and requires specific TCAM configuration, requiring
*   cluster switch to be rebooted before the cluster becomes operational.
*
* - Perform the following steps to ensure proper RCF installation:
*
*   (1) Apply RCF, expect following messages:
*       - Please save config and reload the system...
*       - Edge port type (portfast) should only be enabled on ports...
*       - TCAM region is not configured for feature QoS class IPv4...
*
*   (2) Save running-configuration and reboot Cluster Switch
*
*   (3) After reboot, apply same RCF second time and expect following messages:
*       - % Invalid command at '^' marker
*
*   (4) Save running-configuration again
*
* - If running NX-OS versions 9.3(5) 9.3(6), 9.3(7), or 9.3(8)
*    - Downgrade the NX-OS firmware to version 9.3(5) or earlier if
*      NX-OS using a version later than 9.3(5).
*    - Do not upgrade NX-OS prior to applying v1.9 RCF file.
*    - After the RCF is applied and switch rebooted, then proceed to upgrade
*      NX-OS to version 9.3(5) or later.
*
* - If running 9.3(9) 10.2(2) or later the RCF can be applied to the switch
*      after the upgrade.
*
* - Port 1 multiplexed H/W configuration options:
*     hardware profile front portmode qsfp      (40G H/W port 1/1 is active - default)
*     hardware profile front portmode sfp-plus  (10G H/W ports 1/1/1 - 1/1/4 are active)
*     hardware profile front portmode qsfp      (To reset to QSFP)
*
******************************************************************************
----
====
. Verificare che il file RCF sia la versione più recente corretta:
+
`show running-config`

+
Quando si controlla l'output per verificare che l'RCF sia corretto, assicurarsi che le seguenti informazioni siano corrette:

+
** Il banner RCF
** Le impostazioni di nodo e porta
** Personalizzazioni
+
L'output varia in base alla configurazione del sito. Controllare le impostazioni della porta e fare riferimento alle note di rilascio per eventuali modifiche specifiche all'RCF installato.

+

NOTE: Per informazioni su come portare le porte 10GbE in linea dopo un aggiornamento dell'RCF, consultare l'articolo della Knowledge base https://kb.netapp.com/onprem%2FSwitches%2FCisco%2F10GbE_ports_on_Cisco_3132Q_cluster_switch_do_not_come_online["Le porte 10GbE su uno switch cluster Cisco 3132Q non sono disponibili in linea"^].



. Dopo aver verificato che le versioni RCF e le impostazioni dello switch siano corrette, copiare il file running-config nel file startup-config.
+
Per ulteriori informazioni sui comandi Cisco, consultare la guida appropriata in https://www.cisco.com/c/en/us/support/switches/nexus-3000-series-switches/products-installation-guides-list.html["Cisco Nexus 3000 Series NX-OS Command Reference"^] guide.

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cs2# copy running-config startup-config [########################################] 100% Copy complete
----
====
. Riavviare l'interruttore CS2. È possibile ignorare entrambi gli eventi "cluster ports down" riportati sui nodi durante il riavvio dello switch e l'output dell'errore `% Invalid command at '^' marker` .
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs2# *reload*
This command will reboot the system. (y/n)?  [n] *y*
----
====
. Applicare lo stesso RCF e salvare la configurazione in esecuzione per una seconda volta. Ciò è necessario in quanto l'RCF utilizza QoS e richiede una riconfigurazione del TCAM che comporta il caricamento dell'RCF due volte con lo switch riavviato tra di loro.
+
.Mostra esempio
[%collapsible]
====
[listing]
----
cs2# copy Nexus_3132QV_RCF_v1.6-Cluster-HA-Breakout.txt running-config echo-commands
cs2# copy running-config startup-config [########################################] 100% Copy complete
----
====
. Verificare lo stato delle porte del cluster sul cluster.
+
.. Verificare che le porte del cluster siano funzionanti in tutti i nodi del cluster:
+
`network port show -ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: cluster1-01
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-02
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: cluster1-03
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false

Node: cluster1-04
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/100000 healthy false
e0d       Cluster      Cluster          up   9000  auto/100000 healthy false
----
====
.. Verificare lo stato dello switch dal cluster.
+
`network device-discovery show -protocol cdp`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------- --------
cluster1-01/cdp
            e0a    cs1                       Ethernet1/7       N3K-C3132Q-V
            e0d    cs2                       Ethernet1/7       N3K-C3132Q-V
cluster01-2/cdp
            e0a    cs1                       Ethernet1/8       N3K-C3132Q-V
            e0d    cs2                       Ethernet1/8       N3K-C3132Q-V
cluster01-3/cdp
            e0a    cs1                       Ethernet1/1/1     N3K-C3132Q-V
            e0b    cs2                       Ethernet1/1/1     N3K-C3132Q-V
cluster1-04/cdp
            e0a    cs1                       Ethernet1/1/2     N3K-C3132Q-V
            e0b    cs2                       Ethernet1/1/2     N3K-C3132Q-V

cluster1::*> *system cluster-switch show -is-monitoring-enabled-operational true*
Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- -----
cs1                         cluster-network    10.233.205.90    N3K-C3132Q-V
     Serial Number: FOXXXXXXXGD
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

cs2                         cluster-network    10.233.205.91    N3K-C3132Q-V
     Serial Number: FOXXXXXXXGS
      Is Monitored: true
            Reason: None
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    9.3(4)
    Version Source: CDP

2 entries were displayed.
----
====
+

NOTE: Per ONTAP 9.8 e versioni successive, utilizzare il comando `system switch ethernet show -is-monitoring-enabled-operational true`.

+
[NOTE]
====
A seconda della versione RCF precedentemente caricata sullo switch, sulla console dello switch cs1 potrebbero essere presenti i seguenti output:

[source]
----
2020 Nov 17 16:07:18 cs1 %$ VDC-1 %$ %STP-2-UNBLOCK_CONSIST_PORT: Unblocking port port-channel1 on VLAN0092. Port consistency restored.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_PEER: Blocking port-channel1 on VLAN0001. Inconsistent peer vlan.
2020 Nov 17 16:07:23 cs1 %$ VDC-1 %$ %STP-2-BLOCK_PVID_LOCAL: Blocking port-channel1 on VLAN0092. Inconsistent local vlan.
----
====
+

NOTE: I nodi del cluster possono richiedere fino a 5 minuti per il reporting come integri.



. Sullo switch del cluster cs1, spegnere le porte collegate alle porte del cluster dei nodi.
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1(config)# *interface eth1/1/1-2,eth1/7-8*
cs1(config-if-range)# *shutdown*
----
====
. Verificare che le LIF del cluster siano migrate alle porte ospitate sullo switch cs2. Questa operazione potrebbe richiedere alcuni secondi.
+
`network interface show -vserver Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical            Status     Network            Current             Current Is
Vserver     Interface          Admin/Oper Address/Mask       Node                Port    Home
----------- ------------------ ---------- ------------------ ------------------- ------- ----
Cluster
            cluster1-01_clus1  up/up      169.254.3.4/23     cluster1-01         e0d     false
            cluster1-01_clus2  up/up      169.254.3.5/23     cluster1-01         e0d     true
            cluster1-02_clus1  up/up      169.254.3.8/23     cluster1-02         e0d     false
            cluster1-02_clus2  up/up      169.254.3.9/23     cluster1-02         e0d     true
            cluster1-03_clus1  up/up      169.254.1.3/23     cluster1-03         e0b     false
            cluster1-03_clus2  up/up      169.254.1.1/23     cluster1-03         e0b     true
            cluster1-04_clus1  up/up      169.254.1.6/23     cluster1-04         e0b     false
            cluster1-04_clus2  up/up      169.254.1.7/23     cluster1-04         e0b     true
cluster1::*>
----
====
. Verificare che il cluster funzioni correttamente:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health   Eligibility   Epsilon
-------------------- -------- ------------- -------
cluster1-01          true     true          false
cluster1-02          true     true          false
cluster1-03          true     true          true
cluster1-04          true     true          false
4 entries were displayed.
cluster1::*>
----
====
. Ripetere i passaggi da 1 a 10 sullo switch cs1.
. Abilitare il ripristino automatico sulle LIF del cluster.
+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert True
----
====
. Riavviare lo switch cs1. Questa operazione consente di attivare le LIF del cluster per ripristinare le porte home. È possibile ignorare gli eventi di "interruzione delle porte del cluster" riportati sui nodi durante il riavvio dello switch.
+
[listing, subs="+quotes"]
----
cs1# *reload*
This command will reboot the system. (y/n)?  [n] *y*
----




=== Fase 3: Verificare la configurazione

. Verificare che le porte dello switch collegate alle porte del cluster siano in funzione.
+
`show interface brief | grep up`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show interface brief | grep up*
.
.
Eth1/1/1      1       eth  access up      none                    10G(D) --
Eth1/1/2      1       eth  access up      none                    10G(D) --
Eth1/7        1       eth  trunk  up      none                   100G(D) --
Eth1/8        1       eth  trunk  up      none                   100G(D) --
.
.
----
====
. Verificare che l'ISL tra cs1 e cs2 funzioni correttamente:
+
`show port-channel summary`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cs1# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/31(P)   Eth1/32(P)
cs1#
----
====
. Verificare che le LIF del cluster siano tornate alla porta home:
+
`network interface show -vserver Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*
            Logical            Status     Network            Current             Current Is
Vserver     Interface          Admin/Oper Address/Mask       Node                Port    Home
----------- ------------------ ---------- ------------------ ------------------- ------- ----
Cluster
            cluster1-01_clus1  up/up      169.254.3.4/23     cluster1-01         e0d     true
            cluster1-01_clus2  up/up      169.254.3.5/23     cluster1-01         e0d     true
            cluster1-02_clus1  up/up      169.254.3.8/23     cluster1-02         e0d     true
            cluster1-02_clus2  up/up      169.254.3.9/23     cluster1-02         e0d     true
            cluster1-03_clus1  up/up      169.254.1.3/23     cluster1-03         e0b     true
            cluster1-03_clus2  up/up      169.254.1.1/23     cluster1-03         e0b     true
            cluster1-04_clus1  up/up      169.254.1.6/23     cluster1-04         e0b     true
            cluster1-04_clus2  up/up      169.254.1.7/23     cluster1-04         e0b     true
cluster1::*>
----
====
. Verificare che il cluster funzioni correttamente:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------- -------
cluster1-01          true    true          false
cluster1-02          true    true          false
cluster1-03          true    true          true
cluster1-04          true    true          false
cluster1::*>
----
====
. Eseguire il ping delle interfacce del cluster remoto per verificare la connettività:
+
`cluster ping-cluster -node local`

+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is cluster1-03
Getting addresses from network interface table...
Cluster cluster1-03_clus1 169.254.1.3 cluster1-03 e0a
Cluster cluster1-03_clus2 169.254.1.1 cluster1-03 e0b
Cluster cluster1-04_clus1 169.254.1.6 cluster1-04 e0a
Cluster cluster1-04_clus2 169.254.1.7 cluster1-04 e0b
Cluster cluster1-01_clus1 169.254.3.4 cluster1-01 e0a
Cluster cluster1-01_clus2 169.254.3.5 cluster1-01 e0d
Cluster cluster1-02_clus1 169.254.3.8 cluster1-02 e0a
Cluster cluster1-02_clus2 169.254.3.9 cluster1-02 e0d
Local = 169.254.1.3 169.254.1.1
Remote = 169.254.1.6 169.254.1.7 169.254.3.4 169.254.3.5 169.254.3.8 169.254.3.9
Cluster Vserver Id = 4294967293
Ping status:
............
Basic connectivity succeeds on 12 path(s)
Basic connectivity fails on 0 path(s)
................................................
Detected 9000 byte MTU on 12 path(s):
    Local 169.254.1.3 to Remote 169.254.1.6
    Local 169.254.1.3 to Remote 169.254.1.7
    Local 169.254.1.3 to Remote 169.254.3.4
    Local 169.254.1.3 to Remote 169.254.3.5
    Local 169.254.1.3 to Remote 169.254.3.8
    Local 169.254.1.3 to Remote 169.254.3.9
    Local 169.254.1.1 to Remote 169.254.1.6
    Local 169.254.1.1 to Remote 169.254.1.7
    Local 169.254.1.1 to Remote 169.254.3.4
    Local 169.254.1.1 to Remote 169.254.3.5
    Local 169.254.1.1 to Remote 169.254.3.8
    Local 169.254.1.1 to Remote 169.254.3.9
Larger than PMTU communication succeeds on 12 path(s)
RPC status:
6 paths up, 0 paths down (tcp check)
6 paths up, 0 paths down (udp check)
----
====
. Per ONTAP 9.8 e versioni successive, attivare la funzione di raccolta dei log dello switch Ethernet per la raccolta dei file di log relativi allo switch utilizzando i comandi seguenti:
+
`system switch ethernet log setup-password` e.

+
`system switch ethernet log enable-collection`

+
.. Inserire: `system switch ethernet log setup-password`
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log setup-password*
Enter the switch name: *<return>*
The switch name entered is not recognized.
Choose from the following list:
*cs1*
*cs2*

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *cs1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: *<enter switch password>*
Enter the password again: *<enter switch password>*

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *cs2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: *<enter switch password>*
Enter the password again: *<enter switch password>*
----
====
.. Inserire: `system switch ethernet log enable-collection`
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system  switch ethernet log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
====


+

NOTE: Se uno di questi comandi restituisce un errore, contattare il supporto NetApp.

. Per le release di patch ONTAP 9.5P16, 9.6P12 e 9.7P10 e successive, attivare la funzione di raccolta dei log di Health monitor dello switch Ethernet per la raccolta dei file di log relativi allo switch utilizzando i comandi:
+
`system cluster-switch log setup-password` e.

+
`system cluster-switch log enable-collection`

+
.. Inserire: `system cluster-switch log setup-password`
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system cluster-switch log setup-password*
Enter the switch name: *<return>*
The switch name entered is not recognized.
Choose from the following list:
*cs1*
*cs2*

cluster1::*> *system cluster-switch log setup-password*

Enter the switch name: *cs1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: *<enter switch password>*
Enter the password again: *<enter switch password>*

cluster1::*> *system cluster-switch log setup-password*

Enter the switch name: *cs2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: *<enter switch password>*
Enter the password again: *<enter switch password>*
----
====
.. Inserire: `system cluster-switch log enable-collection`
+
.Mostra esempio
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *system cluster-switch log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
====


+

NOTE: Se uno di questi comandi restituisce un errore, contattare il supporto NetApp.


