---
permalink: switch-cisco-3132q-v/migrate-from-switchless-cluster-to-cisco-nexus-3132q-v.html 
sidebar: sidebar 
keywords: migrate, two-node switched cluster, cisco nexus 3132q-v 
summary: Se si dispone di un cluster senza switch a due nodi, è possibile eseguire la migrazione senza interruzioni a un cluster con switch a due nodi che include switch di rete del cluster Cisco Nexus 3132Q-V. 
---
= Migrare da un cluster senza switch a un cluster con switch a due nodi
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Se si dispone di un cluster senza switch a due nodi, seguire questa procedura per migrare a un cluster con switch a due nodi che include switch di rete del cluster Cisco Nexus 3132Q-V. La procedura di sostituzione è una procedura senza interruzioni (NDO).



== Verifica dei requisiti

.Porte e connessioni a nodi
Assicurarsi di comprendere i requisiti di connessione di porte e nodi e di cablaggio quando si esegue la migrazione a un cluster con switch a due nodi con switch cluster Cisco Nexus 3132Q-V.

* Gli switch del cluster utilizzano le porte ISL (Inter-Switch link) e1/31-32.
* Il link:https://hwu.netapp.com/["Hardware Universe"^] Contiene informazioni sul cablaggio supportato per gli switch Nexus 3132Q-V:
+
** I nodi con connessioni cluster da 10 GbE richiedono moduli ottici QSFP con cavi in fibra breakout o cavi di breakout in rame da QSFP a SFP+.
** I nodi con connessioni cluster da 40/100 GbE richiedono moduli ottici QSFP/QSFP28 supportati con cavi in fibra o cavi a collegamento diretto in rame QSFP/QSFP28.
** Gli switch del cluster utilizzano il cablaggio ISL appropriato: 2 cavi QSFP28 a collegamento diretto in fibra o rame.


* Su Nexus 3132Q-V, è possibile utilizzare le porte QSFP come modalità Ethernet da 40/100 GB o Ethernet da 4 x 10 GB.
+
Per impostazione predefinita, sono disponibili 32 porte in modalità Ethernet da 40/100 GB. Queste porte Ethernet da 40 GB sono numerate con una convenzione di denominazione a 2 tuple. Ad esempio, la seconda porta Ethernet da 40 GB è numerata come 1/2. Il processo di modifica della configurazione da Ethernet 40 GB a Ethernet 10 GB è denominato _breakout_ e il processo di modifica della configurazione da Ethernet 10 GB a Ethernet 40 GB è denominato _breakin_. Quando si scollega una porta Ethernet da 40/100 GB in porte Ethernet da 10 GB, le porte risultanti vengono numerate utilizzando una convenzione di denominazione a 3 tuple. Ad esempio, le porte di breakout della seconda porta Ethernet da 40/100 GB sono numerate come 1/2/1, 1/2/2, 1/2/3, 1/2/4.

* Sul lato sinistro di Nexus 3132Q-V si trova un set di quattro porte SFP+ multiplate alla prima porta QSFP.
+
Per impostazione predefinita, RCF è strutturato in modo da utilizzare la prima porta QSFP.

+
È possibile attivare quattro porte SFP+ invece di una porta QSFP per Nexus 3132Q-V utilizzando `hardware profile front portmode sfp-plus` comando. Allo stesso modo, è possibile reimpostare Nexus 3132Q-V per utilizzare una porta QSFP invece di quattro porte SFP+ utilizzando `hardware profile front portmode qsfp` comando.

* Assicurarsi di aver configurato alcune porte su Nexus 3132Q-V per l'esecuzione a 10 GbE o 40/100 GbE.
+
È possibile suddividere le prime sei porte in modalità 4x10 GbE utilizzando `interface breakout module 1 port 1-6 map 10g-4x` comando. Allo stesso modo, è possibile raggruppare le prime sei porte QSFP+ dalla configurazione breakout utilizzando `no interface breakout module 1 port 1-6 map 10g-4x` comando.

* Il numero di porte 10 GbE e 40/100 GbE è definito nei file di configurazione di riferimento (RCF) disponibili su https://mysupport.netapp.com/NOW/download/software/sanswitch/fcp/Cisco/netapp_cnmn/download.shtml["Download del file di configurazione di riferimento di Cisco ® Cluster Network Switch"^] pagina.


.Di cosa hai bisogno
* Configurazioni correttamente configurate e funzionanti.
* Nodi che eseguono ONTAP 9.4 o versioni successive.
* Tutte le porte del cluster in `up` stato.
* Lo switch cluster Cisco Nexus 3132Q-V è supportato.
* La configurazione di rete del cluster esistente dispone di:
+
** L'infrastruttura cluster Nexus 3132 ridondante e pienamente funzionante su entrambi gli switch.
** Le ultime versioni di RCF e NX-OS sugli switch.
+
Il link:http://mysupport.netapp.com/NOW/download/software/cm_switches/["Switch Ethernet Cisco"^] Contiene informazioni sulle versioni di ONTAP e NX-OS supportate in questa procedura.

** Connettività di gestione su entrambi gli switch.
** Accesso da console a entrambi gli switch.
** Tutte le interfacce logiche del cluster (LIF) in `up` senza essere migrati.
** Personalizzazione iniziale dello switch.
** Tutte le porte ISL abilitate e cablate.




Inoltre, è necessario pianificare, migrare e leggere la documentazione richiesta sulla connettività 10 GbE e 40/100 GbE dai nodi agli switch cluster Nexus 3132Q-V.



== Migrare gli switch

.A proposito degli esempi
Gli esempi di questa procedura utilizzano la seguente nomenclatura di switch e nodi:

* Switch in cluster Nexus 3132Q-V, C1 e C2.
* I nodi sono n1 e n2.


[NOTE]
====
Gli esempi di questa procedura utilizzano due nodi, ciascuno dei quali utilizza due porte di interconnessione cluster e4a e e4e da 40/100 GbE. Il link:https://hwu.netapp.com/["Hardware Universe"^] contiene informazioni dettagliate sulle porte del cluster delle piattaforme.

====
.A proposito di questa attività
Questa procedura descrive i seguenti scenari:

* n1_clus1 è la prima interfaccia logica del cluster (LIF) ad essere collegata allo switch del cluster C1 per il nodo n1.
* n1_clus2 è il primo LIF del cluster ad essere collegato allo switch del cluster C2 per il nodo n1.
* n2_clus1 è il primo LIF del cluster ad essere collegato allo switch del cluster C1 per il nodo n2.
* n2_clus2 è il secondo cluster LIF da collegare allo switch del cluster C2 per il nodo n2.
* Il numero di porte 10 GbE e 40/100 GbE è definito nei file di configurazione di riferimento (RCF) disponibili su https://mysupport.netapp.com/NOW/download/software/sanswitch/fcp/Cisco/netapp_cnmn/download.shtml["Download del file di configurazione di riferimento di Cisco ® Cluster Network Switch"^] pagina.


[NOTE]
====
La procedura richiede l'utilizzo di entrambi i comandi ONTAP e Cisco Nexus 3000 Series Switches; i comandi ONTAP vengono utilizzati se non diversamente indicato.

====
* Il cluster inizia con due nodi connessi e funzionanti in un'impostazione di cluster senza switch a due nodi.
* La prima porta del cluster viene spostata in C1.
* La seconda porta del cluster viene spostata in C2.
* L'opzione cluster senza switch a due nodi è disattivata.




=== Fase 1: Preparazione per la migrazione

. Se AutoSupport è attivato su questo cluster, eliminare la creazione automatica del caso richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all - message MAINT=xh`

+
_x_ è la durata della finestra di manutenzione in ore.

+
[NOTE]
====
Il messaggio AutoSupport informa il supporto tecnico di questa attività di manutenzione in modo che la creazione automatica del caso venga soppressa durante la finestra di manutenzione.

====
. Determinare lo stato amministrativo o operativo di ciascuna interfaccia del cluster:
+
.. Visualizzare gli attributi della porta di rete:
+
`network port show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network port show –role cluster
  (network port show)
Node: n1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e4a       Cluster      Cluster          up   9000 auto/40000  -        -
e4e       Cluster      Cluster          up   9000 auto/40000  -        -

Node: n2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e4a       Cluster      Cluster          up   9000 auto/40000  -        -
e4e       Cluster      Cluster          up   9000 auto/40000  -        -
4 entries were displayed.
----
====
.. Visualizza informazioni sulle interfacce logiche:
+
`network interface show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network interface show -role cluster
 (network interface show)
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            n1_clus1   up/up      10.10.0.1/24       n1            e4a     true
            n1_clus2   up/up      10.10.0.2/24       n1            e4e     true
            n2_clus1   up/up      10.10.0.3/24       n2            e4a     true
            n2_clus2   up/up      10.10.0.4/24       n2            e4e     true
4 entries were displayed.
----
====


. Verificare che gli RCF e l'immagine appropriati siano installati sui nuovi switch 3132Q-V in base alle proprie esigenze e personalizzare il sito in modo essenziale, ad esempio utenti e password, indirizzi di rete e così via.
+
È necessario preparare entrambi gli switch in questa fase. Se è necessario aggiornare il software RCF e delle immagini, attenersi alla seguente procedura:

+
.. Accedere alla link:http://support.netapp.com/NOW/download/software/cm_switches/["Switch Ethernet Cisco"^] Sul sito di supporto NetApp.
.. Annotare lo switch e le versioni software richieste nella tabella riportata in tale pagina.
.. Scaricare la versione appropriata di RCF.
.. Fare clic su *CONTINUA* nella pagina *Descrizione*, accettare il contratto di licenza, quindi seguire le istruzioni nella pagina *Download* per scaricare RCF.
.. Scaricare la versione appropriata del software dell'immagine.


. Fare clic su *CONTINUA* nella pagina *Descrizione*, accettare il contratto di licenza, quindi seguire le istruzioni nella pagina *Download* per scaricare RCF.




=== Fase 2: Spostare la prima porta del cluster su C1

. Sugli switch Nexus 3132Q-V C1 e C2, disattivare tutte le porte C1 e C2 rivolte ai nodi, ma non disattivare le porte ISL.
+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra la disattivazione delle porte da 1 a 30 sugli switch cluster Nexus 3132Q-V C1 e C2 utilizzando una configurazione supportata in RCF `NX3132_RCF_v1.1_24p10g_26p40g.txt`:

[listing]
----
C1# copy running-config startup-config
[########################################] 100%
Copy complete.
C1# configure
C1(config)# int e1/1/1-4,e1/2/1-4,e1/3/1-4,e1/4/1-4,e1/5/1-4,e1/6/1-4,e1/7-30
C1(config-if-range)# shutdown
C1(config-if-range)# exit
C1(config)# exit

C2# copy running-config startup-config
[########################################] 100%
Copy complete.
C2# configure
C2(config)# int e1/1/1-4,e1/2/1-4,e1/3/1-4,e1/4/1-4,e1/5/1-4,e1/6/1-4,e1/7-30
C2(config-if-range)# shutdown
C2(config-if-range)# exit
C2(config)# exit
----
====
. Collegare le porte 1/31 e 1/32 di C1 alle stesse porte di C2 utilizzando i cavi supportati.
. Verificare che le porte ISL siano operative su C1 e C2:
+
`show port-channel summary`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
C1# show port-channel summary
Flags: D - Down         P - Up in port-channel (members)
       I - Individual   H - Hot-standby (LACP only)
       s - Suspended    r - Module-removed
       S - Switched     R - Routed
       U - Up (port-channel)
       M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-        Type   Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)      Eth    LACP      Eth1/31(P)   Eth1/32(P)

C2# show port-channel summary
Flags: D - Down         P - Up in port-channel (members)
       I - Individual   H - Hot-standby (LACP only)
       s - Suspended    r - Module-removed
       S - Switched     R - Routed
       U - Up (port-channel)
       M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-        Type   Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)      Eth    LACP      Eth1/31(P)   Eth1/32(P)
----
====
. Visualizzare l'elenco dei dispositivi vicini sullo switch:
+
`show cdp neighbors`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
C1# show cdp neighbors
Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
C2                 Eth1/31        174    R S I s     N3K-C3132Q-V  Eth1/31
C2                 Eth1/32        174    R S I s     N3K-C3132Q-V  Eth1/32

Total entries displayed: 2

C2# show cdp neighbors
Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
C1                 Eth1/31        178    R S I s     N3K-C3132Q-V  Eth1/31
C1                 Eth1/32        178    R S I s     N3K-C3132Q-V  Eth1/32

Total entries displayed: 2
----
====
. Visualizzare la connettività della porta del cluster su ciascun nodo:
+
`network device-discovery show`

+
.Mostra esempio
[%collapsible]
====
Nell'esempio seguente viene illustrata una configurazione cluster senza switch a due nodi.

[listing]
----
cluster::*> network device-discovery show
            Local  Discovered
Node        Port   Device              Interface        Platform
----------- ------ ------------------- ---------------- ----------------
n1         /cdp
            e4a    n2                  e4a              FAS9000
            e4e    n2                  e4e              FAS9000
n2         /cdp
            e4a    n1                  e4a              FAS9000
            e4e    n1                  e4e              FAS9000
----
====
. Migrare l'interfaccia del clus1 alla porta fisica che ospita il clus2:
+
`network interface migrate`

+
Eseguire questo comando da ciascun nodo locale.

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network interface migrate -vserver Cluster -lif n1_clus1 -source-node n1
–destination-node n1 -destination-port e4e
cluster::*> network interface migrate -vserver Cluster -lif n2_clus1 -source-node n2
–destination-node n2 -destination-port e4e
----
====
. Verificare la migrazione delle interfacce del cluster:
+
`network interface show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----

cluster::*> network interface show -role cluster
 (network interface show)
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            n1_clus1   up/up      10.10.0.1/24       n1            e4e     false
            n1_clus2   up/up      10.10.0.2/24       n1            e4e     true
            n2_clus1   up/up      10.10.0.3/24       n2            e4e     false
            n2_clus2   up/up      10.10.0.4/24       n2            e4e     true
4 entries were displayed.
----
====
. Chiudere il cluster di porte clus1 LIF su entrambi i nodi:
+
`network port modify`

+
[listing]
----
cluster::*> network port modify -node n1 -port e4a -up-admin false
cluster::*> network port modify -node n2 -port e4a -up-admin false
----
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
È possibile utilizzare `network interface check cluster-connectivity` per avviare un controllo di accessibilità per la connettività del cluster e visualizzare i dettagli:

`network interface check cluster-connectivity start` e. `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* attendere alcuni secondi prima di eseguire il comando show per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source          Destination       Packet
Node   Date                       LIF             LIF               Loss
------ -------------------------- --------------- ----------------- -----------
n1
       3/5/2022 19:21:18 -06:00   n1_clus2        n2_clus1      none
       3/5/2022 19:21:20 -06:00   n1_clus2        n2_clus2      none

n2
       3/5/2022 19:21:18 -06:00   n2_clus2        n1_clus1      none
       3/5/2022 19:21:20 -06:00   n2_clus2        n1_clus2      none
----
--
.Tutte le release di ONTAP
--
Per tutte le release di ONTAP, è possibile utilizzare anche `cluster ping-cluster -node <name>` comando per controllare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster::*> *cluster ping-cluster -node n1*
Host is n1
Getting addresses from network interface table...
Cluster n1_clus1 n1		e4a	10.10.0.1
Cluster n1_clus2 n1		e4e	10.10.0.2
Cluster n2_clus1 n2		e4a	10.10.0.3
Cluster n2_clus2 n2		e4e	10.10.0.4

Local = 10.10.0.1 10.10.0.2
Remote = 10.10.0.3 10.10.0.4
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 1500 byte MTU on 32 path(s):
    Local 10.10.0.1 to Remote 10.10.0.3
    Local 10.10.0.1 to Remote 10.10.0.4
    Local 10.10.0.2 to Remote 10.10.0.3
    Local 10.10.0.2 to Remote 10.10.0.4
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
1 paths up, 0 paths down (tcp check)
1 paths up, 0 paths down (ucp check)
----
--
====
. [[step10]]scollegare il cavo da e4a sul nodo n1.
+
Fare riferimento alla configurazione in esecuzione e collegare la prima porta 40 GbE dello switch C1 (porta 1/7 in questo esempio) a e4a su n1 utilizzando il cablaggio supportato su Nexus 3132Q-V.

+

NOTE: Quando si ricollegano i cavi a un nuovo switch cluster Cisco, i cavi utilizzati devono essere in fibra o supportati da Cisco.

. Scollegare il cavo da e4a sul nodo n2.
+
È possibile fare riferimento alla configurazione in esecuzione e collegare e4a alla successiva porta 40 GbE disponibile su C1, porta 1/8, utilizzando i cavi supportati.

. Abilitare tutte le porte rivolte al nodo su C1.
+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra le porte da 1 a 30 abilitate sugli switch cluster Nexus 3132Q-V C1 e C2 utilizzando la configurazione supportata in RCF `NX3132_RCF_v1.1_24p10g_26p40g.txt`:

[listing]
----
C1# configure
C1(config)# int e1/1/1-4,e1/2/1-4,e1/3/1-4,e1/4/1-4,e1/5/1-4,e1/6/1-4,e1/7-30
C1(config-if-range)# no shutdown
C1(config-if-range)# exit
C1(config)# exit
----
====
. Abilitare la prima porta del cluster, e4a, su ciascun nodo:
+
`network port modify`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network port modify -node n1 -port e4a -up-admin true
cluster::*> network port modify -node n2 -port e4a -up-admin true
----
====
. Verificare che i cluster siano attivi su entrambi i nodi:
+
`network port show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network port show –role cluster
  (network port show)
Node: n1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e4a       Cluster      Cluster          up   9000 auto/40000  -        -
e4e       Cluster      Cluster          up   9000 auto/40000  -        -

Node: n2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e4a       Cluster      Cluster          up   9000 auto/40000  -        -
e4e       Cluster      Cluster          up   9000 auto/40000  -        -
4 entries were displayed.
----
====
. Per ciascun nodo, ripristinare tutte le LIF di interconnessione del cluster migrate:
+
`network interface revert`

+
.Mostra esempio
[%collapsible]
====
Nell'esempio seguente vengono riportati i file LIF migrati alle porte home.

[listing]
----
cluster::*> network interface revert -vserver Cluster -lif n1_clus1
cluster::*> network interface revert -vserver Cluster -lif n2_clus1
----
====
. Verificare che tutte le porte di interconnessione del cluster siano ora ripristinate alle porte home:
+
`network interface show`

+
Il `Is Home` la colonna deve visualizzare un valore di `true` per tutte le porte elencate in `Current Port` colonna. Se il valore visualizzato è `false`, la porta non è stata ripristinata.

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network interface show -role cluster
 (network interface show)
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            n1_clus1   up/up      10.10.0.1/24       n1            e4a     true
            n1_clus2   up/up      10.10.0.2/24       n1            e4e     true
            n2_clus1   up/up      10.10.0.3/24       n2            e4a     true
            n2_clus2   up/up      10.10.0.4/24       n2            e4e     true
4 entries were displayed.
----
====




=== Fase 3: Spostare la seconda porta del cluster su C2

. Visualizzare la connettività della porta del cluster su ciascun nodo:
+
`network device-discovery show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network device-discovery show
            Local  Discovered
Node        Port   Device              Interface        Platform
----------- ------ ------------------- ---------------- ----------------
n1         /cdp
            e4a    C1                  Ethernet1/7      N3K-C3132Q-V
            e4e    n2                  e4e              FAS9000
n2         /cdp
            e4a    C1                  Ethernet1/8      N3K-C3132Q-V
            e4e    n1                  e4e              FAS9000
----
====
. Sulla console di ciascun nodo, migrare il clus2 alla porta e4a:
+
`network interface migrate`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network interface migrate -vserver Cluster -lif n1_clus2 -source-node n1
–destination-node n1 -destination-port e4a
cluster::*> network interface migrate -vserver Cluster -lif n2_clus2 -source-node n2
–destination-node n2 -destination-port e4a
----
====
. Chiudere il cluster di porte clus2 LIF su entrambi i nodi:
+
`network port modify`

+
L'esempio seguente mostra le porte specificate che vengono chiuse su entrambi i nodi:

+
[listing]
----
	cluster::*> network port modify -node n1 -port e4e -up-admin false
	cluster::*> network port modify -node n2 -port e4e -up-admin false
----
. Verificare lo stato LIF del cluster:
+
`network interface show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network interface show -role cluster
 (network interface show)
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            n1_clus1   up/up      10.10.0.1/24       n1            e4a     true
            n1_clus2   up/up      10.10.0.2/24       n1            e4a     false
            n2_clus1   up/up      10.10.0.3/24       n2            e4a     true
            n2_clus2   up/up      10.10.0.4/24       n2            e4a     false
4 entries were displayed.
----
====
. Scollegare il cavo da e4e sul nodo n1.
+
Fare riferimento alla configurazione in esecuzione e collegare la prima porta 40 GbE dello switch C2 (porta 1/7 in questo esempio) a e4e su n1 utilizzando il cablaggio supportato su Nexus 3132Q-V.

. Scollegare il cavo da e4e sul nodo n2.
+
È possibile fare riferimento alla configurazione in esecuzione e collegare e4e alla successiva porta 40 GbE disponibile su C2, porta 1/8, utilizzando i cavi supportati.

. Abilitare tutte le porte rivolte al nodo su C2.
+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra le porte da 1 a 30 abilitate sugli switch cluster Nexus 3132Q-V C1 e C2 utilizzando una configurazione supportata in RCF `NX3132_RCF_v1.1_24p10g_26p40g.txt`:

[listing]
----
C2# configure
C2(config)# int e1/1/1-4,e1/2/1-4,e1/3/1-4,e1/4/1-4,e1/5/1-4,e1/6/1-4,e1/7-30
C2(config-if-range)# no shutdown
C2(config-if-range)# exit
C2(config)# exit
----
====
. Abilitare la seconda porta del cluster, e4e, su ciascun nodo:
+
`network port modify`

+
L'esempio seguente mostra le porte specificate che vengono avviate:

+
[listing]
----
	cluster::*> network port modify -node n1 -port e4e -up-admin true
	cluster::*> network port modify -node n2 -port e4e -up-admin true
----
. Per ciascun nodo, ripristinare tutte le LIF di interconnessione del cluster migrate:
+
`network interface revert`

+
Nell'esempio seguente vengono riportati i file LIF migrati alle porte home.

+
[listing]
----
	cluster::*> network interface revert -vserver Cluster -lif n1_clus2
	cluster::*> network interface revert -vserver Cluster -lif n2_clus2
----
. Verificare che tutte le porte di interconnessione del cluster siano ora ripristinate alle porte home:
+
`network interface show`

+
Il `Is Home` la colonna deve visualizzare un valore di `true` per tutte le porte elencate in `Current Port` colonna. Se il valore visualizzato è `false`, la porta non è stata ripristinata.

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network interface show -role cluster
 (network interface show)
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            n1_clus1   up/up      10.10.0.1/24       n1            e4a     true
            n1_clus2   up/up      10.10.0.2/24       n1            e4e     true
            n2_clus1   up/up      10.10.0.3/24       n2            e4a     true
            n2_clus2   up/up      10.10.0.4/24       n2            e4e     true
4 entries were displayed.
----
====
. Verificare che tutte le porte di interconnessione del cluster si trovino in `up` stato.
+
`network port show –role cluster`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> network port show –role cluster
  (network port show)
Node: n1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e4a       Cluster      Cluster          up   9000 auto/40000  -        -
e4e       Cluster      Cluster          up   9000 auto/40000  -        -

Node: n2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e4a       Cluster      Cluster          up   9000 auto/40000  -        -
e4e       Cluster      Cluster          up   9000 auto/40000  -        -
4 entries were displayed.
----
====




=== Fase 4: Disattivare l'opzione cluster senza switch a due nodi

. Visualizzare i numeri di porta dello switch del cluster a cui ciascuna porta del cluster è collegata su ciascun nodo:
+
`network device-discovery show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
	cluster::*> network device-discovery show
            Local  Discovered
Node        Port   Device              Interface        Platform
----------- ------ ------------------- ---------------- ----------------
n1         /cdp
            e4a    C1                  Ethernet1/7      N3K-C3132Q-V
            e4e    C2                  Ethernet1/7      N3K-C3132Q-V
n2         /cdp
            e4a    C1                  Ethernet1/8      N3K-C3132Q-V
            e4e    C2                  Ethernet1/8      N3K-C3132Q-V
----
====
. Switch del cluster rilevati e monitorati:
+
`system cluster-switch show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> system cluster-switch show

Switch                      Type               Address          Model
--------------------------- ------------------ ---------------- ---------------
C1                         cluster-network     10.10.1.101      NX3132V
     Serial Number: FOX000001
      Is Monitored: true
            Reason:
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    7.0(3)I4(1)
    Version Source: CDP

C2                          cluster-network     10.10.1.102      NX3132V
     Serial Number: FOX000002
      Is Monitored: true
            Reason:
  Software Version: Cisco Nexus Operating System (NX-OS) Software, Version
                    7.0(3)I4(1)
    Version Source: CDP

2 entries were displayed.
----
====
. Disattivare le impostazioni di configurazione senza switch a due nodi su qualsiasi nodo:
+
`network options switchless-cluster`

+
[listing]
----
network options switchless-cluster modify -enabled false
----
. Verificare che il `switchless-cluster` l'opzione è stata disattivata.
+
[listing]
----
network options switchless-cluster show
----




=== Fase 5: Verificare la configurazione

. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
È possibile utilizzare `network interface check cluster-connectivity` per avviare un controllo di accessibilità per la connettività del cluster e visualizzare i dettagli:

`network interface check cluster-connectivity start` e. `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* attendere alcuni secondi prima di eseguire il comando show per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source          Destination       Packet
Node   Date                       LIF             LIF               Loss
------ -------------------------- --------------- ----------------- -----------
n1
       3/5/2022 19:21:18 -06:00   n1_clus2        n2_clus1      none
       3/5/2022 19:21:20 -06:00   n1_clus2        n2_clus2      none

n2
       3/5/2022 19:21:18 -06:00   n2_clus2        n1_clus1      none
       3/5/2022 19:21:20 -06:00   n2_clus2        n1_clus2      none
----
--
.Tutte le release di ONTAP
--
Per tutte le release di ONTAP, è possibile utilizzare anche `cluster ping-cluster -node <name>` comando per controllare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster::*> *cluster ping-cluster -node n1*
Host is n1
Getting addresses from network interface table...
Cluster n1_clus1 n1		e4a	10.10.0.1
Cluster n1_clus2 n1		e4e	10.10.0.2
Cluster n2_clus1 n2		e4a	10.10.0.3
Cluster n2_clus2 n2		e4e	10.10.0.4

Local = 10.10.0.1 10.10.0.2
Remote = 10.10.0.3 10.10.0.4
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 1500 byte MTU on 32 path(s):
    Local 10.10.0.1 to Remote 10.10.0.3
    Local 10.10.0.1 to Remote 10.10.0.4
    Local 10.10.0.2 to Remote 10.10.0.3
    Local 10.10.0.2 to Remote 10.10.0.4
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
1 paths up, 0 paths down (tcp check)
1 paths up, 0 paths down (ucp check)
----
--
====
. [[step2]]se è stata eliminata la creazione automatica del caso, riattivarla richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.Quali sono le prossime novità?
link:../switch-cshm/config-overview.html["Configurare il monitoraggio dello stato dello switch"].
