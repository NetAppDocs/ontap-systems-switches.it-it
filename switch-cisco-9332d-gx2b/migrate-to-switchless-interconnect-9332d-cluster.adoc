---
permalink: switch-cisco-9332d-gx2b/migrate-to-switchless-interconnect-9332d-cluster.html 
sidebar: sidebar 
keywords: migrate, switchless cluster interconnect, cisco nexus switch 9332D-GX2B2 
summary: È possibile migrare da un cluster con una rete di cluster commutata a uno in cui due nodi sono collegati direttamente per ONTAP 9.3 e versioni successive. 
---
= Sostituisci gli switch cluster Cisco Nexus 9332D-GX2B2 con connessioni switchless
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
È possibile migrare da un cluster con una rete di cluster commutata a uno in cui due nodi sono collegati direttamente per ONTAP 9.3 e versioni successive.



== Requisiti di revisione

.Linee guida
Rivedere le seguenti linee guida:

* La migrazione a una configurazione cluster switchless a due nodi è un'operazione non distruttiva.  La maggior parte dei sistemi ha due porte di interconnessione cluster dedicate su ciascun nodo, ma è possibile utilizzare questa procedura anche per sistemi con un numero maggiore di porte di interconnessione cluster dedicate su ciascun nodo, ad esempio quattro, sei o otto.
* Non è possibile utilizzare la funzionalità di interconnessione del cluster senza switch con più di due nodi.
* Se si dispone di un cluster a due nodi esistente che utilizza switch di interconnessione cluster ed esegue ONTAP 9.3 o versione successiva, è possibile sostituire gli switch con connessioni dirette back-to-back tra i nodi.


.Prima di iniziare
Assicurati di avere quanto segue:

* Un cluster sano costituito da due nodi collegati tramite switch di cluster.  I nodi devono eseguire la stessa versione ONTAP .
* Ogni nodo con il numero richiesto di porte cluster dedicate, che forniscono connessioni di interconnessione cluster ridondanti per supportare la configurazione del sistema.  Ad esempio, ci sono due porte ridondanti per un sistema con due porte di interconnessione cluster dedicate su ciascun nodo.




== Migrare gli switch

.Informazioni su questo compito
La seguente procedura rimuove gli switch del cluster in un cluster a due nodi e sostituisce ogni connessione allo switch con una connessione diretta al nodo partner.

image::../media/tnsc_clusterswitches_and_direct_connections.PNG[Interruttori cluster sostituiti con connessioni dirette]

.Informazioni sugli esempi
Gli esempi nella seguente procedura mostrano nodi che utilizzano "e0a" e "e0b" come porte del cluster.  I nodi potrebbero utilizzare porte cluster diverse, poiché variano in base al sistema.



=== Fase 1: Prepararsi alla migrazione

. Cambia il livello di privilegio in avanzato, inserendo `y` quando viene richiesto di continuare:
+
`set -privilege advanced`

+
Il prompt avanzato `*>` appare.

. ONTAP 9.3 e versioni successive supportano il rilevamento automatico dei cluster switchless, abilitato per impostazione predefinita.
+
È possibile verificare che il rilevamento dei cluster switchless sia abilitato eseguendo il comando con privilegi avanzati:

+
`network options detect-switchless-cluster show`

+
.Mostra esempio
[%collapsible]
====
Il seguente output di esempio mostra se l'opzione è abilitata.

[listing]
----
cluster::*> network options detect-switchless-cluster show
   (network options detect-switchless-cluster show)
Enable Switchless Cluster Detection: true
----
====
+
Se "Abilita rilevamento cluster senza switch" è `false` , contattare l'assistenza NetApp .

. Se AutoSupport è abilitato su questo cluster, sopprimere la creazione automatica dei casi richiamando un messaggio AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=<number_of_hours>h`

+
Dove `h` è la durata della finestra di manutenzione in ore.  Il messaggio avvisa il supporto tecnico di questa attività di manutenzione, in modo che possa sopprimere la creazione automatica dei casi durante la finestra di manutenzione.

+
Nell'esempio seguente, il comando sopprime la creazione automatica dei casi per due ore:

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=2h
----
====




=== Passaggio 2: configurare porte e cablaggio

. Organizzare le porte del cluster su ogni switch in gruppi in modo che le porte del cluster nel gruppo 1 vadano al cluster switch 1 e le porte del cluster nel gruppo 2 vadano al cluster switch 2.  Questi gruppi saranno necessari più avanti nella procedura.
. Identificare le porte del cluster e verificare lo stato e l'integrità del collegamento:
+
`network port show -ipspace Cluster`

+
Nell'esempio seguente per i nodi con porte cluster "e0a" e "e0b", un gruppo è identificato come "nodo1:e0a" e "nodo2:e0a" e l'altro gruppo come "nodo1:e0b" e "nodo2:e0b".  I nodi potrebbero utilizzare porte cluster diverse perché variano in base al sistema.

+
image::../media/tnsc_clusterswitch_connections.PNG[Connessioni dello switch cluster tra node1 e node2]

+
Verificare che le porte abbiano un valore di `up` per la colonna “Link” e un valore di `healthy` per la colonna “Stato di salute”.

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::> network port show -ipspace Cluster
Node: node1
                                                                 Ignore
                                             Speed(Mbps) Health  Health
Port  IPspace   Broadcast Domain Link  MTU   Admin/Oper	 Status  Status
----- --------- ---------------- ----- ----- ----------- ------- -------
e0a   Cluster   Cluster          up    9000  auto/10000  healthy false
e0b   Cluster   Cluster          up    9000  auto/10000  healthy false

Node: node2
                                                                 Ignore
                                             Speed(Mbps) Health  Health
Port  IPspace   Broadcast Domain Link  MTU   Admin/Oper	 Status  Status
----- --------- ---------------- ----- ----- ----------- ------- -------
e0a   Cluster   Cluster          up    9000  auto/10000  healthy false
e0b   Cluster   Cluster          up    9000  auto/10000  healthy false
4 entries were displayed.
----
====
. Verificare che tutti i LIF del cluster siano sulle rispettive porte home.
+
Verificare che la colonna "is-home" sia `true` per ciascuno dei LIF del cluster:

+
`network interface show -vserver Cluster -fields is-home`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster::*> net int show -vserver Cluster -fields is-home
(network interface show)
vserver  lif          is-home
-------- ------------ --------
Cluster  node1_clus1  true
Cluster  node1_clus2  true
Cluster  node2_clus1  true
Cluster  node2_clus2  true
4 entries were displayed.
----
====
+
Se sono presenti LIF del cluster che non si trovano sulle loro porte home, ripristinare tali LIF sulle loro porte home:

+
`network interface revert -vserver Cluster -lif *`

. Disabilitare il ripristino automatico per i LIF del cluster:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

. Verificare che tutte le porte elencate nel passaggio precedente siano connesse a uno switch di rete:
+
`network device-discovery show -port _cluster_port_`

+
La colonna "Dispositivo rilevato" dovrebbe contenere il nome dello switch del cluster a cui è connessa la porta.

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra che le porte del cluster "e0a" e "e0b" sono collegate correttamente agli switch del cluster "cs1" e "cs2".

[listing]
----
cluster::> network device-discovery show -port e0a|e0b
  (network device-discovery show)
Node/     Local  Discovered
Protocol  Port   Device (LLDP: ChassisID)  Interface  Platform
--------- ------ ------------------------- ---------- ----------
node1/cdp
          e0a    cs1                       0/11       BES-53248
          e0b    cs2                       0/12       BES-53248
node2/cdp
          e0a    cs1                       0/9        BES-53248
          e0b    cs2                       0/9        BES-53248
4 entries were displayed.
----
====
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
Puoi usare il `network interface check cluster-connectivity` comando per avviare un controllo di accessibilità per la connettività del cluster e quindi visualizzare i dettagli:

`network interface check cluster-connectivity start`E `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* Attendere alcuni secondi prima di eseguire il `show` comando per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Tutte le versioni ONTAP
--
Per tutte le versioni ONTAP , è anche possibile utilizzare `cluster ping-cluster -node <name>` comando per verificare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:

Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)

Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[step7]] Verificare che il cluster sia integro:
+
`cluster ring show`

+
Tutte le unità devono essere master o secondarie.

. Impostare la configurazione senza switch per le porte del gruppo 1.
+

IMPORTANT: Per evitare potenziali problemi di rete, è necessario scollegare le porte dal gruppo 1 e ricollegarle una dopo l'altra il più rapidamente possibile, ad esempio *in meno di 20 secondi*.

+
.. Scollegare contemporaneamente tutti i cavi dalle porte del gruppo 1.
+
Nell'esempio seguente, i cavi vengono scollegati dalla porta "e0a" su ciascun nodo e il traffico del cluster continua attraverso lo switch e la porta "e0b" su ciascun nodo:

+
image::../media/tnsc_clusterswitch1_disconnected.PNG[ClusterSwitch1 disconnesso]

.. Collegare le porte del gruppo 1 una dietro l'altra.
+
Nell'esempio seguente, "e0a" sul nodo 1 è connesso a "e0a" sul nodo 2:

+
image::../media/tnsc_ports_e0a_direct_connection.PNG[Collegamento diretto tra le porte "e0a"]



. L'opzione di rete cluster senza switch passa da `false` A `true` .  L'operazione potrebbe richiedere fino a 45 secondi.  Verificare che l'opzione senza interruttore sia impostata su `true` :
+
`network options switchless-cluster show`

+
L'esempio seguente mostra che il cluster switchless è abilitato:

+
[listing]
----
cluster::*> network options switchless-cluster show
Enable Switchless Cluster: true
----
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
Puoi usare il `network interface check cluster-connectivity` comando per avviare un controllo di accessibilità per la connettività del cluster e quindi visualizzare i dettagli:

`network interface check cluster-connectivity start`E `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* Attendere alcuni secondi prima di eseguire il `show` comando per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Tutte le versioni ONTAP
--
Per tutte le versioni ONTAP , è anche possibile utilizzare `cluster ping-cluster -node <name>` comando per verificare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:

Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)

Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====

IMPORTANT: Prima di procedere al passaggio successivo, è necessario attendere almeno due minuti per confermare una connessione back-to-back funzionante sul gruppo 1.

. [[step11]] Impostare la configurazione senza switch per le porte nel gruppo 2.
+

IMPORTANT: Per evitare potenziali problemi di rete, è necessario scollegare le porte dal gruppo 2 e ricollegarle una dopo l'altra il più rapidamente possibile, ad esempio *in meno di 20 secondi*.

+
.. Scollegare contemporaneamente tutti i cavi dalle porte del gruppo 2.
+
Nell'esempio seguente, i cavi vengono scollegati dalla porta "e0b" su ciascun nodo e il traffico del cluster continua tramite la connessione diretta tra le porte "e0a":

+
image::../media/tnsc_clusterswitch2_disconnected.PNG[ClusterSwitch2 disconnesso]

.. Cablare le porte del gruppo 2 una dietro l'altra.
+
Nell'esempio seguente, "e0a" sul nodo 1 è connesso a "e0a" sul nodo 2 e "e0b" sul nodo 1 è connesso a "e0b" sul nodo 2:

+
image::../media/tnsc_node1_and_node2_direct_connection.PNG[Connessione diretta tra le porte sul nodo 1 e sul nodo 2]







=== Passaggio 3: verificare la configurazione

. Verificare che le porte su entrambi i nodi siano collegate correttamente:
+
`network device-discovery show -port _cluster_port_`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra che le porte del cluster "e0a" e "e0b" sono correttamente collegate alla porta corrispondente sul partner del cluster:

[listing]
----
cluster::> net device-discovery show -port e0a|e0b
  (network device-discovery show)
Node/      Local  Discovered
Protocol   Port   Device (LLDP: ChassisID)  Interface  Platform
---------- ------ ------------------------- ---------- ----------
node1/cdp
           e0a    node2                     e0a        AFF-A300
           e0b    node2                     e0b        AFF-A300
node1/lldp
           e0a    node2 (00:a0:98:da:16:44) e0a        -
           e0b    node2 (00:a0:98:da:16:44) e0b        -
node2/cdp
           e0a    node1                     e0a        AFF-A300
           e0b    node1                     e0b        AFF-A300
node2/lldp
           e0a    node1 (00:a0:98:da:87:49) e0a        -
           e0b    node1 (00:a0:98:da:87:49) e0b        -
8 entries were displayed.
----
====
. Riattivare il ripristino automatico per i LIF del cluster:
+
`network interface modify -vserver Cluster -lif * -auto-revert true`

. Verificare che tutti i LIF siano a casa. Potrebbero volerci alcuni secondi.
+
`network interface show -vserver Cluster -lif _lif_name_`

+
.Mostra esempio
[%collapsible]
====
I LIF sono stati ripristinati se la colonna "È a casa" è `true` , come mostrato per `node1_clus2` E `node2_clus2` nell'esempio seguente:

[listing]
----
cluster::> network interface show -vserver Cluster -fields curr-port,is-home
vserver  lif           curr-port is-home
-------- ------------- --------- -------
Cluster  node1_clus1   e0a       true
Cluster  node1_clus2   e0b       true
Cluster  node2_clus1   e0a       true
Cluster  node2_clus2   e0b       true
4 entries were displayed.
----
====
+
Se uno qualsiasi dei LIFS del cluster non è tornato alle proprie porte home, ripristinarlo manualmente dal nodo locale:

+
`network interface revert -vserver Cluster -lif _lif_name_`

. Controllare lo stato del cluster dei nodi dalla console di sistema di uno dei due nodi:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
L'esempio seguente mostra epsilon su entrambi i nodi da `false` :

[listing]
----
Node  Health  Eligibility Epsilon
----- ------- ----------- --------
node1 true    true        false
node2 true    true        false
2 entries were displayed.
----
====
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
Puoi usare il `network interface check cluster-connectivity` comando per avviare un controllo di accessibilità per la connettività del cluster e quindi visualizzare i dettagli:

`network interface check cluster-connectivity start`E `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* Attendere alcuni secondi prima di eseguire il `show` comando per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Tutte le versioni ONTAP
--
Per tutte le versioni ONTAP , è anche possibile utilizzare `cluster ping-cluster -node <name>` comando per verificare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:

Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)

Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[step6]] Se hai disattivato la creazione automatica dei casi, riattivala richiamando un messaggio AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`

+
Per maggiori informazioni, vedere link:https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/How_to_suppress_automatic_case_creation_during_scheduled_maintenance_windows_-_ONTAP_9["Articolo 1010449 della Knowledge Base NetApp : Come sopprimere la creazione automatica di casi durante le finestre di manutenzione programmata"^].

. Ripristinare il livello di privilegio su amministratore:
+
`set -privilege admin`


