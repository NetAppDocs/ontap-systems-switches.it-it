---
permalink: switch-cisco-9336c-fx2/replace-9336c-cluster.html 
sidebar: sidebar 
keywords: replacing, replace, defective, nexus, switch, cluster, network, nondisruptive, procedure, ndu, replace a cisco nexus 9336c-fx2 cluster switch - cisco nexus 9336c-fx2 
summary: La sostituzione di uno switch Nexus 9336C-FX2 difettoso in una rete cluster è una procedura senza interruzioni. 
---
= Sostituire uno switch cluster Cisco Nexus 9336C-FX2
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Per sostituire uno switch Nexus 9336C-FX2 difettoso in una rete cluster, procedere come segue. Si tratta di una procedura senza interruzioni (NDU).



== Verifica dei requisiti

Prima di sostituire lo switch, assicurarsi che:

* Sul cluster e sull'infrastruttura di rete esistenti:
+
** Il cluster esistente viene verificato come completamente funzionale, con almeno uno switch del cluster completamente connesso.
** Tutte le porte del cluster sono *up*.
** Tutte le interfacce logiche del cluster (LIFF) sono *up* e sulle porte home.
** ONTAP `cluster ping-cluster -node node1` Il comando deve indicare che la connettività di base e le comunicazioni di dimensioni superiori a quelle di PMTU hanno esito positivo su tutti i percorsi.


* Sullo switch sostitutivo Nexus 9336C-FX2:
+
** La connettività di rete di gestione sullo switch sostitutivo è funzionale.
** L'accesso della console allo switch sostitutivo è in posizione.
** Le connessioni dei nodi sono le porte da 1/1 a 1/34.
** Tutte le porte ISL (Inter-Switch link) sono disattivate sulle porte 1/35 e 1/36.
** Il file di configurazione di riferimento desiderato (RCF) e lo switch dell'immagine del sistema operativo NX-OS vengono caricati sullo switch.
** La personalizzazione iniziale dello switch è completa, come descritto in link:setup-switch-9336c-cluster.html["Configurare lo switch del cluster 9336C-FX2"].
+
Tutte le personalizzazioni precedenti del sito, come STP, SNMP e SSH, vengono copiate nel nuovo switch.



* È stato eseguito il comando per la migrazione di un LIF del cluster dal nodo in cui è ospitato il LIF del cluster.




== Sostituire lo switch

.A proposito degli esempi
Gli esempi di questa procedura utilizzano la seguente nomenclatura di switch e nodi:

* I nomi degli switch Nexus 9336C-FX2 esistenti sono cs1 e cs2.
* Il nome del nuovo switch Nexus 9336C-FX2 è newcs2.
* I nomi dei nodi sono node1 e node2.
* Le porte del cluster su ciascun nodo sono denominate e0a e e0b.
* I nomi LIF del cluster sono node1_clus1 e node1_clus2 per node1 e node2_clus1 e node2_clus2 per node2.
* Il prompt per le modifiche a tutti i nodi del cluster è cluster1:*>


.A proposito di questa attività
La seguente procedura si basa sulla seguente topologia di rete del cluster:

.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> network port show -ipspace Cluster

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false
4 entries were displayed.



cluster1::*> network interface show -vserver Cluster
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e0b     true
4 entries were displayed.



cluster1::*> network device-discovery show -protocol cdp
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       Eth1/2            N9K-C9336C
            e0b    cs2                       Eth1/2            N9K-C9336C
node1      /cdp
            e0a    cs1                       Eth1/1            N9K-C9336C
            e0b    cs2                       Eth1/1            N9K-C9336C
4 entries were displayed.



cs1# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         144    H           FAS2980       e0a
node2              Eth1/2         145    H           FAS2980       e0a
cs2                Eth1/35        176    R S I s     N9K-C9336C    Eth1/35
cs2(FDO220329V5)   Eth1/36        176    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4


cs2# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         139    H           FAS2980       e0b
node2              Eth1/2         124    H           FAS2980       e0b
cs1                Eth1/35        178    R S I s     N9K-C9336C    Eth1/35
cs1                Eth1/36        178    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4
----
====


=== Fase 1: Preparazione per la sostituzione

. Se AutoSupport è attivato su questo cluster, eliminare la creazione automatica del caso richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
dove x è la durata della finestra di manutenzione in ore.

+

NOTE: Il messaggio AutoSupport informa il supporto tecnico di questa attività di manutenzione in modo che la creazione automatica del caso venga soppressa durante la finestra di manutenzione.

. Installare l'RCF e l'immagine appropriati sullo switch, newcs2, ed eseguire le operazioni necessarie per la preparazione del sito.
+
Se necessario, verificare, scaricare e installare le versioni appropriate del software RCF e NX-OS per il nuovo switch. Se il nuovo switch è stato configurato correttamente e non sono necessari aggiornamenti per il software RCF e NX-OS, passare alla fase 2.

+
.. Accedere alla _pagina Descrizione del file di configurazione di riferimento per gli switch di rete di gestione e cluster NetApp_ sul sito del supporto NetApp.
.. Fare clic sul link per la _matrice di compatibilità della rete di gestione e di rete del cluster_, quindi annotare la versione del software dello switch richiesta.
.. Fare clic sulla freccia indietro del browser per tornare alla pagina Descrizione, fare clic su *CONTINUA*, accettare il contratto di licenza e accedere alla pagina Download.
.. Seguire la procedura riportata nella pagina di download per scaricare i file RCF e NX-OS corretti per la versione del software ONTAP che si sta installando.


. Sul nuovo switch, accedere come admin e chiudere tutte le porte che verranno collegate alle interfacce del cluster di nodi (porte da 1/1 a 1/34).
+
Se lo switch che si sta sostituendo non funziona e viene spento, passare alla fase 4. Le LIF sui nodi del cluster dovrebbero essere già riuscite a eseguire il failover sull'altra porta del cluster per ciascun nodo.

+
.Mostra esempio
[%collapsible]
====
[listing]
----
newcs2# config
Enter configuration commands, one per line. End with CNTL/Z.
newcs2(config)# interface e1/1-34
newcs2(config-if-range)# shutdown
----
====
. Verificare che tutte le LIF del cluster abbiano attivato l'autorevert:
+
`network interface show -vserver Cluster -fields auto-revert`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::> network interface show -vserver Cluster -fields auto-revert

             Logical
Vserver      Interface     Auto-revert
------------ ------------- -------------
Cluster      node1_clus1   true
Cluster      node1_clus2   true
Cluster      node2_clus1   true
Cluster      node2_clus2   true

4 entries were displayed.
----
====
. Verificare che tutte le LIF del cluster siano in grado di comunicare:
+
`cluster ping-cluster`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> cluster ping-cluster node1

Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
====




=== Fase 2: Configurazione di cavi e porte

. Spegnere le porte ISL 1/35 e 1/36 dello switch Nexus 9336C-FX2 cs1.
+
.Mostra esempio
[%collapsible]
====
[listing]
----
cs1# configure
Enter configuration commands, one per line. End with CNTL/Z.
cs1(config)# interface e1/35-36
cs1(config-if-range)# shutdown
cs1(config-if-range)#
----
====
. Rimuovere tutti i cavi dallo switch Nexus 9336C-FX2 cs2, quindi collegarli alle stesse porte dello switch Nexus C9336C-FX2 newcs2.
. Richiamare le porte ISL 1/35 e 1/36 tra gli switch cs1 e newcs2, quindi verificare lo stato di funzionamento del canale della porta.
+
Port-Channel deve indicare PO1(su) e Member Ports deve indicare eth1/35(P) e eth1/36(P).

+
.Mostra esempio
[%collapsible]
====
Questo esempio abilita le porte ISL 1/35 e 1/36 e visualizza il riepilogo del canale delle porte sullo switch cs1:

[listing]
----
cs1# configure
Enter configuration commands, one per line. End with CNTL/Z.
cs1(config)# int e1/35-36
cs1(config-if-range)# no shutdown

cs1(config-if-range)# show port-channel summary
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member       Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/35(P)   Eth1/36(P)

cs1(config-if-range)#
----
====
. Verificare che la porta e0b sia attiva su tutti i nodi:
+
`network port show ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
L'output dovrebbe essere simile a quanto segue:

[listing]
----
cluster1::*> network port show -ipspace Cluster

Node: node1
                                                                        Ignore
                                                   Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ----- ----------- -------- -------
e0a       Cluster      Cluster          up   9000  auto/10000  healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000  healthy  false

Node: node2
                                                                        Ignore
                                                   Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ----- ----------- -------- -------
e0a       Cluster      Cluster          up   9000  auto/10000  healthy  false
e0b       Cluster      Cluster          up   9000  auto/auto   -        false

4 entries were displayed.
----
====
. Sullo stesso nodo utilizzato nella fase precedente, ripristinare la LIF del cluster associata alla porta nella fase precedente utilizzando il comando di revert dell'interfaccia di rete.
+
.Mostra esempio
[%collapsible]
====
In questo esempio, LIF node1_clus2 su node1 viene invertito correttamente se il valore Home è true e la porta è e0b.

I seguenti comandi restituiscono LIF `node1_clus2` acceso `node1` alla porta home `e0a` E visualizza le informazioni sui LIF su entrambi i nodi. L'attivazione del primo nodo ha esito positivo se la colonna is Home è vera per entrambe le interfacce del cluster e mostra le assegnazioni di porta corrette, in questo esempio `e0a` e. `e0b` al nodo1.

[listing]
----
cluster1::*> network interface show -vserver Cluster

            Logical      Status     Network            Current    Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node       Port    Home
----------- ------------ ---------- ------------------ ---------- ------- -----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1      e0a     true
            node1_clus2  up/up      169.254.49.125/16  node1      e0b     true
            node2_clus1  up/up      169.254.47.194/16  node2      e0a     true
            node2_clus2  up/up      169.254.19.183/16  node2      e0a     false

4 entries were displayed.
----
====
. Visualizzare le informazioni sui nodi di un cluster:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
Questo esempio mostra che l'integrità del nodo per node1 e node2 in questo cluster è vera:

[listing]
----
cluster1::*> cluster show

Node          Health  Eligibility
------------- ------- ------------
node1         false   true
node2         true    true
----
====
. Verificare che tutte le porte del cluster fisico siano installate:
+
`network port show ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> network port show -ipspace Cluster

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e0a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e0b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e0a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e0b       Cluster      Cluster          up    9000  auto/10000  healthy  false

4 entries were displayed.
----
====
. Verificare che tutte le LIF del cluster siano in grado di comunicare:
+
`cluster ping-cluster`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> cluster ping-cluster -node node2
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
====
. Confermare la seguente configurazione di rete del cluster:
+
`network port show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> network port show -ipspace Cluster
Node: node1
                                                                       Ignore
                                       Speed(Mbps)            Health   Health
Port      IPspace     Broadcast Domain Link MTU   Admin/Oper  Status   Status
--------- ----------- ---------------- ---- ----- ----------- -------- ------
e0a       Cluster     Cluster          up   9000  auto/10000  healthy  false
e0b       Cluster     Cluster          up   9000  auto/10000  healthy  false

Node: node2
                                                                       Ignore
                                        Speed(Mbps)           Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000 auto/10000  healthy  false
e0b       Cluster      Cluster          up   9000 auto/10000  healthy  false

4 entries were displayed.


cluster1::*> network interface show -vserver Cluster

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e0b     true

4 entries were displayed.

cluster1::> network device-discovery show -protocol cdp

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       0/2               N9K-C9336C
            e0b    newcs2                    0/2               N9K-C9336C
node1      /cdp
            e0a    cs1                       0/1               N9K-C9336C
            e0b    newcs2                    0/1               N9K-C9336C

4 entries were displayed.


cs1# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID            Local Intrfce  Hldtme Capability  Platform      Port ID
node1                Eth1/1         144    H           FAS2980       e0a
node2                Eth1/2         145    H           FAS2980       e0a
newcs2               Eth1/35        176    R S I s     N9K-C9336C    Eth1/35
newcs2               Eth1/36        176    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4


cs2# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         139    H           FAS2980       e0b
node2              Eth1/2         124    H           FAS2980       e0b
cs1                Eth1/35        178    R S I s     N9K-C9336C    Eth1/35
cs1                Eth1/36        178    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4
----
====




=== Fase 3: Verificare la configurazione

. Per ONTAP 9.8 e versioni successive, attivare la funzione di raccolta dei log dello switch Ethernet per la raccolta dei file di log relativi allo switch, utilizzando i comandi seguenti:
+
`system switch ethernet log setup-password` e. `system switch ethernet log enable-collection`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> system switch ethernet log setup-password
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
cs1
cs2

cluster1::*> system switch ethernet log setup-password

Enter the switch name: cs1
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] y

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> system switch ethernet log setup-password

Enter the switch name: cs2
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] y

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> system  switch ethernet log enable-collection

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] y

Enabling cluster switch log collection.

cluster1::*>
----
====
+

NOTE: Se uno di questi comandi restituisce un errore, contattare il supporto NetApp.

. Per le release di patch ONTAP 9.5P16, 9.6P12 e 9.7P10 e successive, attivare la funzione di raccolta dei log di Health monitor dello switch Ethernet per la raccolta dei file di log relativi allo switch, utilizzando i comandi:
+
`system cluster-switch log setup-password` e. `system cluster-switch log enable-collection`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> system cluster-switch log setup-password
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
cs1
cs2

cluster1::*> system cluster-switch log setup-password

Enter the switch name: cs1
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] y

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> system cluster-switch log setup-password

Enter the switch name: cs2
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] y

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> system cluster-switch log enable-collection

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] y

Enabling cluster switch log collection.

cluster1::*>
----
====
+

NOTE: Se uno di questi comandi restituisce un errore, contattare il supporto NetApp.

. Se è stata eliminata la creazione automatica del caso, riattivarla richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=END`


