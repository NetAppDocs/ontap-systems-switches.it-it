---
permalink: switch-cisco-9336c-fx2/replace-9336c-cluster.html 
sidebar: sidebar 
keywords: replacing, replace, defective, nexus, switch, cluster, network, nondisruptive, procedure, ndu, replace a cisco nexus 9336c-fx2 cluster switch - cisco nexus 9336c-fx2 
summary: La sostituzione di uno switch Nexus 9336C-FX2 difettoso in una rete cluster è una procedura senza interruzioni. 
---
= Sostituisci gli switch cluster Cisco Nexus 9336C-FX2 e 9336C-FX2-T
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Per sostituire gli switch Nexus 9336C-FX2 e 9336C-FX2-T difettosi in una rete cluster, seguire questi passaggi. Si tratta di una procedura non distruttiva (NDU).



== Verifica dei requisiti

Prima di sostituire lo switch, assicurarsi che:

* È stato verificato il numero di serie dello switch per assicurarsi che venga sostituito l'interruttore corretto.
* Sul cluster e sull'infrastruttura di rete esistenti:
+
** Il cluster esistente viene verificato come completamente funzionale, con almeno uno switch del cluster completamente connesso.
** Tutte le porte del cluster sono *up*.
** Tutte le interfacce logiche del cluster (LIFF) sono *up* e sulle porte home.
** ONTAP `cluster ping-cluster -node node1` Il comando deve indicare che la connettività di base e le comunicazioni di dimensioni superiori a quelle di PMTU hanno esito positivo su tutti i percorsi.


* Sullo switch sostitutivo Nexus 9336C-FX2:
+
** La connettività di rete di gestione sullo switch sostitutivo è funzionale.
** L'accesso della console allo switch sostitutivo è in posizione.
** Le connessioni dei nodi sono le porte da 1/1 a 1/34.
** Tutte le porte ISL (Inter-Switch link) sono disattivate sulle porte 1/35 e 1/36.
** Il file di configurazione di riferimento desiderato (RCF) e lo switch dell'immagine del sistema operativo NX-OS vengono caricati sullo switch.
** La personalizzazione iniziale dello switch è completa, come descritto in link:setup-switch-9336c-cluster.html["Configurare lo switch del cluster 9336C-FX2"].
+
Tutte le personalizzazioni precedenti del sito, come STP, SNMP e SSH, vengono copiate nel nuovo switch.



* È stato eseguito il comando per la migrazione di un LIF del cluster dal nodo in cui è ospitato il LIF del cluster.




== Attivare la registrazione della console

NetApp consiglia vivamente di attivare la registrazione della console sui dispositivi in uso e di eseguire le seguenti operazioni quando si sostituisce lo switch:

* Lasciare attivato AutoSupport durante la manutenzione.
* Attivare un AutoSupport di manutenzione prima e dopo la manutenzione per disattivare la creazione del caso per tutta la durata della manutenzione. Consultare questo articolo della Knowledge base https://kb.netapp.com/Support_Bulletins/Customer_Bulletins/SU92["SU92: Come eliminare la creazione automatica dei casi durante le finestre di manutenzione programmata"^] per ulteriori dettagli.
* Attivare la registrazione della sessione per qualsiasi sessione CLI. Per istruzioni su come attivare la registrazione della sessione, consultare la sezione "registrazione dell'output della sessione" in questo articolo della Knowledge base https://kb.netapp.com/on-prem/ontap/Ontap_OS/OS-KBs/How_to_configure_PuTTY_for_optimal_connectivity_to_ONTAP_systems["Come configurare Putty per una connettività ottimale ai sistemi ONTAP"^].




== Sostituire lo switch

.A proposito degli esempi
Gli esempi di questa procedura utilizzano la seguente nomenclatura di switch e nodi:

* I nomi degli switch Nexus 9336C-FX2 esistenti sono cs1 e cs2.
* Il nome del nuovo switch Nexus 9336C-FX2 è newcs2.
* I nomi dei nodi sono node1 e node2.
* Le porte del cluster su ciascun nodo sono denominate e0a e e0b.
* I nomi LIF del cluster sono node1_clus1 e node1_clus2 per node1 e node2_clus1 e node2_clus2 per node2.
* Il prompt per le modifiche a tutti i nodi del cluster è cluster1:*>


.A proposito di questa attività
La seguente procedura si basa sulla seguente topologia di rete del cluster:

.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> network port show -ipspace Cluster

Node: node1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false

Node: node2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000 healthy  false
4 entries were displayed.



cluster1::*> network interface show -vserver Cluster
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e0b     true
4 entries were displayed.



cluster1::*> network device-discovery show -protocol cdp
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       Eth1/2            N9K-C9336C
            e0b    cs2                       Eth1/2            N9K-C9336C
node1      /cdp
            e0a    cs1                       Eth1/1            N9K-C9336C
            e0b    cs2                       Eth1/1            N9K-C9336C
4 entries were displayed.



cs1# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         144    H           FAS2980       e0a
node2              Eth1/2         145    H           FAS2980       e0a
cs2                Eth1/35        176    R S I s     N9K-C9336C    Eth1/35
cs2(FDO220329V5)   Eth1/36        176    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4


cs2# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         139    H           FAS2980       e0b
node2              Eth1/2         124    H           FAS2980       e0b
cs1                Eth1/35        178    R S I s     N9K-C9336C    Eth1/35
cs1                Eth1/36        178    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4
----
====


=== Fase 1: Preparazione per la sostituzione

. Se AutoSupport è attivato su questo cluster, eliminare la creazione automatica del caso richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
dove x è la durata della finestra di manutenzione in ore.

+

NOTE: Il messaggio AutoSupport informa il supporto tecnico di questa attività di manutenzione in modo che la creazione automatica del caso venga soppressa durante la finestra di manutenzione.

. Installare l'RCF e l'immagine appropriati sullo switch, newcs2, ed eseguire le operazioni necessarie per la preparazione del sito.
+
Se necessario, verificare, scaricare e installare le versioni appropriate del software RCF e NX-OS per il nuovo switch. Se il nuovo switch è stato configurato correttamente e non sono necessari aggiornamenti per il software RCF e NX-OS, passare alla fase 2.

+
.. Accedere alla _pagina Descrizione del file di configurazione di riferimento per gli switch di rete di gestione e cluster NetApp_ sul sito del supporto NetApp.
.. Fare clic sul link per la _matrice di compatibilità della rete di gestione e di rete del cluster_, quindi annotare la versione del software dello switch richiesta.
.. Fare clic sulla freccia indietro del browser per tornare alla pagina Descrizione, fare clic su *CONTINUA*, accettare il contratto di licenza e accedere alla pagina Download.
.. Seguire la procedura riportata nella pagina di download per scaricare i file RCF e NX-OS corretti per la versione del software ONTAP che si sta installando.


. Sul nuovo switch, accedere come admin e chiudere tutte le porte che verranno collegate alle interfacce del cluster di nodi (porte da 1/1 a 1/34).
+
Se lo switch che si sta sostituendo non funziona e viene spento, passare alla fase 4. Le LIF sui nodi del cluster dovrebbero essere già riuscite a eseguire il failover sull'altra porta del cluster per ciascun nodo.

+
.Mostra esempio
[%collapsible]
====
[listing]
----
newcs2# config
Enter configuration commands, one per line. End with CNTL/Z.
newcs2(config)# interface e1/1-34
newcs2(config-if-range)# shutdown
----
====
. Verificare che tutte le LIF del cluster abbiano attivato l'autorevert:
+
`network interface show -vserver Cluster -fields auto-revert`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::> network interface show -vserver Cluster -fields auto-revert

             Logical
Vserver      Interface     Auto-revert
------------ ------------- -------------
Cluster      node1_clus1   true
Cluster      node1_clus2   true
Cluster      node2_clus1   true
Cluster      node2_clus2   true

4 entries were displayed.
----
====
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
È possibile utilizzare `network interface check cluster-connectivity` per avviare un controllo di accessibilità per la connettività del cluster e visualizzare i dettagli:

`network interface check cluster-connectivity start` e. `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* attendere alcuni secondi prima di eseguire il `show` comando per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Tutte le release di ONTAP
--
Per tutte le release di ONTAP, è possibile utilizzare anche `cluster ping-cluster -node <name>` comando per controllare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====


=== Fase 2: Configurazione di cavi e porte

. Spegnere le porte ISL 1/35 e 1/36 dello switch Nexus 9336C-FX2 cs1.
+
.Mostra esempio
[%collapsible]
====
[listing]
----
cs1# configure
Enter configuration commands, one per line. End with CNTL/Z.
cs1(config)# interface e1/35-36
cs1(config-if-range)# shutdown
cs1(config-if-range)#
----
====
. Rimuovere tutti i cavi dallo switch Nexus 9336C-FX2 cs2, quindi collegarli alle stesse porte dello switch Nexus C9336C-FX2 newcs2.
. Richiamare le porte ISL 1/35 e 1/36 tra gli switch cs1 e newcs2, quindi verificare lo stato di funzionamento del canale della porta.
+
Port-Channel deve indicare PO1(su) e Member Ports deve indicare eth1/35(P) e eth1/36(P).

+
.Mostra esempio
[%collapsible]
====
Questo esempio abilita le porte ISL 1/35 e 1/36 e visualizza il riepilogo del canale delle porte sullo switch cs1:

[listing]
----
cs1# configure
Enter configuration commands, one per line. End with CNTL/Z.
cs1(config)# int e1/35-36
cs1(config-if-range)# no shutdown

cs1(config-if-range)# show port-channel summary
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member       Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/35(P)   Eth1/36(P)

cs1(config-if-range)#
----
====
. Verificare che la porta e0b sia attiva su tutti i nodi:
+
`network port show ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
L'output dovrebbe essere simile a quanto segue:

[listing]
----
cluster1::*> network port show -ipspace Cluster

Node: node1
                                                                        Ignore
                                                   Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ----- ----------- -------- -------
e0a       Cluster      Cluster          up   9000  auto/10000  healthy  false
e0b       Cluster      Cluster          up   9000  auto/10000  healthy  false

Node: node2
                                                                        Ignore
                                                   Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ----- ----------- -------- -------
e0a       Cluster      Cluster          up   9000  auto/10000  healthy  false
e0b       Cluster      Cluster          up   9000  auto/auto   -        false

4 entries were displayed.
----
====
. Sullo stesso nodo utilizzato nella fase precedente, ripristinare la LIF del cluster associata alla porta nella fase precedente utilizzando il comando di revert dell'interfaccia di rete.
+
.Mostra esempio
[%collapsible]
====
In questo esempio, LIF node1_clus2 su node1 viene invertito correttamente se il valore Home è true e la porta è e0b.

I seguenti comandi restituiscono LIF `node1_clus2` acceso `node1` alla porta home `e0a` E visualizza le informazioni sui LIF su entrambi i nodi. L'attivazione del primo nodo ha esito positivo se la colonna is Home è vera per entrambe le interfacce del cluster e mostra le assegnazioni di porta corrette, in questo esempio `e0a` e. `e0b` al nodo1.

[listing]
----
cluster1::*> network interface show -vserver Cluster

            Logical      Status     Network            Current    Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node       Port    Home
----------- ------------ ---------- ------------------ ---------- ------- -----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1      e0a     true
            node1_clus2  up/up      169.254.49.125/16  node1      e0b     true
            node2_clus1  up/up      169.254.47.194/16  node2      e0a     true
            node2_clus2  up/up      169.254.19.183/16  node2      e0a     false

4 entries were displayed.
----
====
. Visualizzare le informazioni sui nodi di un cluster:
+
`cluster show`

+
.Mostra esempio
[%collapsible]
====
Questo esempio mostra che l'integrità del nodo per node1 e node2 in questo cluster è vera:

[listing]
----
cluster1::*> cluster show

Node          Health  Eligibility
------------- ------- ------------
node1         false   true
node2         true    true
----
====
. Verificare che tutte le porte del cluster fisico siano installate:
+
`network port show ipspace Cluster`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> network port show -ipspace Cluster

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e0a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e0b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e0a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e0b       Cluster      Cluster          up    9000  auto/10000  healthy  false

4 entries were displayed.
----
====
. Verificare la connettività delle interfacce del cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e versioni successive
--
È possibile utilizzare `network interface check cluster-connectivity` per avviare un controllo di accessibilità per la connettività del cluster e visualizzare i dettagli:

`network interface check cluster-connectivity start` e. `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* attendere alcuni secondi prima di eseguire il `show` comando per visualizzare i dettagli.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Tutte le release di ONTAP
--
Per tutte le release di ONTAP, è possibile utilizzare anche `cluster ping-cluster -node <name>` comando per controllare la connettività:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====


=== Fase 3: Verificare la configurazione

. Confermare la seguente configurazione di rete del cluster:
+
`network port show`

+
.Mostra esempio
[%collapsible]
====
[listing]
----
cluster1::*> network port show -ipspace Cluster
Node: node1
                                                                       Ignore
                                       Speed(Mbps)            Health   Health
Port      IPspace     Broadcast Domain Link MTU   Admin/Oper  Status   Status
--------- ----------- ---------------- ---- ----- ----------- -------- ------
e0a       Cluster     Cluster          up   9000  auto/10000  healthy  false
e0b       Cluster     Cluster          up   9000  auto/10000  healthy  false

Node: node2
                                                                       Ignore
                                        Speed(Mbps)           Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000 auto/10000  healthy  false
e0b       Cluster      Cluster          up   9000 auto/10000  healthy  false

4 entries were displayed.


cluster1::*> network interface show -vserver Cluster

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e0a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e0b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e0a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e0b     true

4 entries were displayed.

cluster1::> network device-discovery show -protocol cdp

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e0a    cs1                       0/2               N9K-C9336C
            e0b    newcs2                    0/2               N9K-C9336C
node1      /cdp
            e0a    cs1                       0/1               N9K-C9336C
            e0b    newcs2                    0/1               N9K-C9336C

4 entries were displayed.


cs1# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID            Local Intrfce  Hldtme Capability  Platform      Port ID
node1                Eth1/1         144    H           FAS2980       e0a
node2                Eth1/2         145    H           FAS2980       e0a
newcs2               Eth1/35        176    R S I s     N9K-C9336C    Eth1/35
newcs2               Eth1/36        176    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4


cs2# show cdp neighbors

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         139    H           FAS2980       e0b
node2              Eth1/2         124    H           FAS2980       e0b
cs1                Eth1/35        178    R S I s     N9K-C9336C    Eth1/35
cs1                Eth1/36        178    R S I s     N9K-C9336C    Eth1/36

Total entries displayed: 4
----
====
. Se è stata eliminata la creazione automatica del caso, riattivarla richiamando un messaggio AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.Quali sono le prossime novità?
Dopo aver sostituito gli interruttori,link:../switch-cshm/config-overview.html["configurare il monitoraggio dello stato dello switch"] .
